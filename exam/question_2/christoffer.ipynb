{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# ----- Tensorflow -----\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from keras import regularizers as reg\n",
    "from keras import optimizers as opt\n",
    "from keras.models import Model, load_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "from keras.layers import Input, Dropout, Dense, Conv2D, MaxPooling2D, Flatten, Concatenate, AveragePooling2D\n",
    "\n",
    "# ----- plot -----\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ----- Utility functions -----\n",
    "from utils import load_data, plot_hist\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'C:/Users/chrse/Desktop/project_aml'\n",
    "BATCH_SIZE = 32\n",
    "train, test, val = load_data(data_dir, perc=1, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architectures\n",
    "- Consider and discuss alternative CNN model architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- ResNet -----\n",
    "inputs = Input(shape=(96,96,3))\n",
    "x = Conv2D(filters=48, kernel_size=11, activation='relu')(inputs)\n",
    "x = MaxPooling2D((3, 3) )(x)\n",
    "x = Conv2D(filters=128, kernel_size=5, activation='relu')(x)\n",
    "x = MaxPooling2D((3, 3) )(x)\n",
    "x = Conv2D(filters=192, kernel_size=3, activation='relu')(x)\n",
    "x = Conv2D(filters=192, kernel_size=3, activation='relu')(x)\n",
    "x = Conv2D(filters=128, kernel_size=3, activation='relu')(x)\n",
    "#x = MaxPooling2D((3, 3), strides=(2,2) )(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "outputs = Dense(2, activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "#x = AveragePooling2D(pool_size=2)(x)\n",
    "#x = Conv2D(filters=6, kernel_size=3, activation='relu')(x)\n",
    "#x = AveragePooling2D(pool_size=2)(x)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# ----- Configure model -----\n",
    "model.compile(optimizer=opt.Nadam(learning_rate=0.0002),\n",
    "\tloss='categorical_crossentropy',\n",
    "\tmetrics=['accuracy'])\n",
    "\n",
    "# ----- Train model -----\n",
    "history = model.fit(train, epochs = 15, validation_data= val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 96, 96, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_45 (Conv2D)          (None, 86, 86, 48)        17472     \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 86, 86, 48)        0         \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 28, 28, 48)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_46 (Conv2D)          (None, 24, 24, 128)       153728    \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_47 (Conv2D)          (None, 6, 6, 192)         221376    \n",
      "                                                                 \n",
      " conv2d_48 (Conv2D)          (None, 4, 4, 192)         331968    \n",
      "                                                                 \n",
      " conv2d_49 (Conv2D)          (None, 2, 2, 128)         221312    \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 2, 2, 128)         0         \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,372,994\n",
      "Trainable params: 1,372,994\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "23/82 [=======>......................] - ETA: 25s - loss: 0.6961 - accuracy: 0.4823"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\chrse\\Desktop\\applied_ML_faelles\\exam\\question_2\\christoffer.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/christoffer.ipynb#W6sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mopt\u001b[39m.\u001b[39mNadam(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.0002\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/christoffer.ipynb#W6sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \tloss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/christoffer.ipynb#W6sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \tmetrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/christoffer.ipynb#W6sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m# ----- Train model -----\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/christoffer.ipynb#W6sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train, epochs \u001b[39m=\u001b[39;49m \u001b[39m30\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m val)\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ----- ResNet -----\n",
    "inputs = Input(shape=(96,96,3))\n",
    "x = Conv2D(filters=48, kernel_size=11, activation='relu')(inputs)\n",
    "x = Dropout(0.3)(x)\n",
    "x = MaxPooling2D((3, 3) )(x)\n",
    "x = Conv2D(filters=128, kernel_size=5, activation='relu')(x)\n",
    "x = MaxPooling2D((3, 3) )(x)\n",
    "x = Conv2D(filters=192, kernel_size=3, activation='relu')(x)\n",
    "x = Conv2D(filters=192, kernel_size=3, activation='relu')(x)\n",
    "x = Conv2D(filters=128, kernel_size=3, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "#x = MaxPooling2D((3, 3), strides=(2,2) )(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "outputs = Dense(2, activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "#x = AveragePooling2D(pool_size=2)(x)\n",
    "#x = Conv2D(filters=6, kernel_size=3, activation='relu')(x)\n",
    "#x = AveragePooling2D(pool_size=2)(x)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# ----- Configure model -----\n",
    "model.compile(optimizer=opt.Nadam(learning_rate=0.0002),\n",
    "\tloss='categorical_crossentropy',\n",
    "\tmetrics=['accuracy'])\n",
    "\n",
    "# ----- Train model -----\n",
    "history = model.fit(train, epochs = 30, validation_data= val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(None, 96, 96, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_60 (Conv2D)          (None, 86, 86, 48)        17472     \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 86, 86, 48)        0         \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPoolin  (None, 28, 28, 48)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_61 (Conv2D)          (None, 24, 24, 128)       153728    \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_62 (Conv2D)          (None, 6, 6, 192)         221376    \n",
      "                                                                 \n",
      " conv2d_63 (Conv2D)          (None, 4, 4, 192)         331968    \n",
      "                                                                 \n",
      " conv2d_64 (Conv2D)          (None, 2, 2, 128)         221312    \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 2, 2, 128)         0         \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,372,994\n",
      "Trainable params: 1,372,994\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "82/82 [==============================] - 37s 434ms/step - loss: 0.6969 - accuracy: 0.5212 - val_loss: 0.6911 - val_accuracy: 0.5762\n",
      "Epoch 2/30\n",
      "82/82 [==============================] - 36s 433ms/step - loss: 0.6911 - accuracy: 0.5300 - val_loss: 0.6919 - val_accuracy: 0.7073\n",
      "Epoch 3/30\n",
      "82/82 [==============================] - 33s 399ms/step - loss: 0.6920 - accuracy: 0.5548 - val_loss: 0.6905 - val_accuracy: 0.6402\n",
      "Epoch 4/30\n",
      "82/82 [==============================] - 33s 398ms/step - loss: 0.6790 - accuracy: 0.5952 - val_loss: 0.6836 - val_accuracy: 0.5549\n",
      "Epoch 5/30\n",
      "82/82 [==============================] - 33s 397ms/step - loss: 0.6660 - accuracy: 0.5952 - val_loss: 0.6472 - val_accuracy: 0.5945\n",
      "Epoch 6/30\n",
      "82/82 [==============================] - 34s 414ms/step - loss: 0.6390 - accuracy: 0.6551 - val_loss: 0.6188 - val_accuracy: 0.6524\n",
      "Epoch 7/30\n",
      "82/82 [==============================] - 32s 396ms/step - loss: 0.6068 - accuracy: 0.6849 - val_loss: 0.5400 - val_accuracy: 0.7835\n",
      "Epoch 8/30\n",
      "82/82 [==============================] - 34s 420ms/step - loss: 0.5844 - accuracy: 0.6971 - val_loss: 0.5233 - val_accuracy: 0.7835\n",
      "Epoch 9/30\n",
      "82/82 [==============================] - 34s 413ms/step - loss: 0.5499 - accuracy: 0.7303 - val_loss: 0.5155 - val_accuracy: 0.7591\n",
      "Epoch 10/30\n",
      "82/82 [==============================] - 34s 408ms/step - loss: 0.5455 - accuracy: 0.7268 - val_loss: 0.5020 - val_accuracy: 0.7835\n",
      "Epoch 11/30\n",
      "82/82 [==============================] - 33s 408ms/step - loss: 0.5224 - accuracy: 0.7463 - val_loss: 0.4749 - val_accuracy: 0.7957\n",
      "Epoch 12/30\n",
      "82/82 [==============================] - 33s 401ms/step - loss: 0.5127 - accuracy: 0.7573 - val_loss: 0.4717 - val_accuracy: 0.7957\n",
      "Epoch 13/30\n",
      "82/82 [==============================] - 33s 403ms/step - loss: 0.5030 - accuracy: 0.7562 - val_loss: 0.4654 - val_accuracy: 0.7927\n",
      "Epoch 14/30\n",
      "82/82 [==============================] - 33s 408ms/step - loss: 0.4931 - accuracy: 0.7676 - val_loss: 0.4605 - val_accuracy: 0.7957\n",
      "Epoch 15/30\n",
      "82/82 [==============================] - 34s 409ms/step - loss: 0.4884 - accuracy: 0.7669 - val_loss: 0.4689 - val_accuracy: 0.7927\n",
      "Epoch 16/30\n",
      "82/82 [==============================] - 33s 400ms/step - loss: 0.4760 - accuracy: 0.7821 - val_loss: 0.4503 - val_accuracy: 0.8049\n",
      "Epoch 17/30\n",
      "82/82 [==============================] - 33s 399ms/step - loss: 0.4666 - accuracy: 0.7890 - val_loss: 0.4542 - val_accuracy: 0.7927\n",
      "Epoch 18/30\n",
      "82/82 [==============================] - 33s 404ms/step - loss: 0.4640 - accuracy: 0.7863 - val_loss: 0.4490 - val_accuracy: 0.8140\n",
      "Epoch 19/30\n",
      "82/82 [==============================] - 33s 397ms/step - loss: 0.4627 - accuracy: 0.7909 - val_loss: 0.4422 - val_accuracy: 0.7957\n",
      "Epoch 20/30\n",
      "82/82 [==============================] - 33s 407ms/step - loss: 0.4442 - accuracy: 0.8047 - val_loss: 0.4360 - val_accuracy: 0.8079\n",
      "Epoch 21/30\n",
      "82/82 [==============================] - 34s 412ms/step - loss: 0.4323 - accuracy: 0.8115 - val_loss: 0.4355 - val_accuracy: 0.8018\n",
      "Epoch 22/30\n",
      "82/82 [==============================] - 33s 407ms/step - loss: 0.4240 - accuracy: 0.8134 - val_loss: 0.4560 - val_accuracy: 0.7774\n",
      "Epoch 23/30\n",
      "82/82 [==============================] - 34s 409ms/step - loss: 0.4127 - accuracy: 0.8249 - val_loss: 0.4828 - val_accuracy: 0.7652\n",
      "Epoch 24/30\n",
      "82/82 [==============================] - 35s 428ms/step - loss: 0.3950 - accuracy: 0.8314 - val_loss: 0.4321 - val_accuracy: 0.8262\n",
      "Epoch 25/30\n",
      "82/82 [==============================] - 34s 415ms/step - loss: 0.3809 - accuracy: 0.8432 - val_loss: 0.4797 - val_accuracy: 0.7896\n",
      "Epoch 26/30\n",
      "82/82 [==============================] - 36s 437ms/step - loss: 0.3672 - accuracy: 0.8447 - val_loss: 0.4738 - val_accuracy: 0.8079\n",
      "Epoch 27/30\n",
      "82/82 [==============================] - 33s 406ms/step - loss: 0.3417 - accuracy: 0.8615 - val_loss: 0.5137 - val_accuracy: 0.8018\n",
      "Epoch 28/30\n",
      "82/82 [==============================] - 33s 401ms/step - loss: 0.3348 - accuracy: 0.8642 - val_loss: 0.4754 - val_accuracy: 0.8049\n",
      "Epoch 29/30\n",
      "82/82 [==============================] - 33s 399ms/step - loss: 0.3436 - accuracy: 0.8604 - val_loss: 0.4945 - val_accuracy: 0.8018\n",
      "Epoch 30/30\n",
      "82/82 [==============================] - 33s 402ms/step - loss: 0.2808 - accuracy: 0.8920 - val_loss: 0.5255 - val_accuracy: 0.8018\n"
     ]
    }
   ],
   "source": [
    "# ----- ResNet -----\n",
    "inputs = Input(shape=(96,96,3))\n",
    "x = Conv2D(filters=48, kernel_size=11, activation='relu')(inputs)\n",
    "x = Dropout(0.3)(x)\n",
    "x = MaxPooling2D((3, 3) )(x)\n",
    "x = Conv2D(filters=128, kernel_size=5, activation='relu')(x)\n",
    "x = MaxPooling2D((3, 3) )(x)\n",
    "x = Conv2D(filters=192, kernel_size=3, activation='relu')(x)\n",
    "x = Conv2D(filters=192, kernel_size=3, activation='relu')(x)\n",
    "x = Conv2D(filters=128, kernel_size=3, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "#x = MaxPooling2D((3, 3), strides=(2,2) )(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "\n",
    "outputs = Dense(2, activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "#x = AveragePooling2D(pool_size=2)(x)\n",
    "#x = Conv2D(filters=6, kernel_size=3, activation='relu')(x)\n",
    "#x = AveragePooling2D(pool_size=2)(x)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# ----- Configure model -----\n",
    "model.compile(optimizer=opt.Nadam(learning_rate=0.0002),\n",
    "\tloss='categorical_crossentropy',\n",
    "\tmetrics=['accuracy'])\n",
    "\n",
    "# ----- Train model -----\n",
    "history = model.fit(train, epochs = 30, validation_data= val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 96, 96, 3)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 86, 86, 48)        17472     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 86, 86, 48)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 28, 28, 48)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 128)       153728    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 8, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 6, 6, 192)         221376    \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 4, 4, 192)         331968    \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 2, 2, 128)         221312    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 2, 2, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               65664     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               131584    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,177,154\n",
      "Trainable params: 1,177,154\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "82/82 [==============================] - 34s 396ms/step - loss: 0.6941 - accuracy: 0.5303 - val_loss: 0.6863 - val_accuracy: 0.5854\n",
      "Epoch 2/30\n",
      "82/82 [==============================] - 32s 390ms/step - loss: 0.6904 - accuracy: 0.5380 - val_loss: 0.6748 - val_accuracy: 0.7409\n",
      "Epoch 3/30\n",
      "82/82 [==============================] - 32s 394ms/step - loss: 0.6807 - accuracy: 0.5910 - val_loss: 0.6381 - val_accuracy: 0.7530\n",
      "Epoch 4/30\n",
      "82/82 [==============================] - 32s 390ms/step - loss: 0.6786 - accuracy: 0.6158 - val_loss: 0.6820 - val_accuracy: 0.5366\n",
      "Epoch 5/30\n",
      "82/82 [==============================] - 32s 390ms/step - loss: 0.6865 - accuracy: 0.5853 - val_loss: 0.6890 - val_accuracy: 0.5396\n",
      "Epoch 6/30\n",
      "82/82 [==============================] - 32s 394ms/step - loss: 0.6525 - accuracy: 0.6234 - val_loss: 0.6572 - val_accuracy: 0.6128\n",
      "Epoch 7/30\n",
      "82/82 [==============================] - 32s 388ms/step - loss: 0.6307 - accuracy: 0.6501 - val_loss: 0.6649 - val_accuracy: 0.6128\n",
      "Epoch 8/30\n",
      "82/82 [==============================] - 32s 390ms/step - loss: 0.5817 - accuracy: 0.7035 - val_loss: 0.5345 - val_accuracy: 0.7774\n",
      "Epoch 9/30\n",
      "82/82 [==============================] - 32s 396ms/step - loss: 0.5565 - accuracy: 0.7318 - val_loss: 0.5253 - val_accuracy: 0.7591\n",
      "Epoch 10/30\n",
      "82/82 [==============================] - 32s 389ms/step - loss: 0.5342 - accuracy: 0.7394 - val_loss: 0.4810 - val_accuracy: 0.7927\n",
      "Epoch 11/30\n",
      "82/82 [==============================] - 32s 389ms/step - loss: 0.5265 - accuracy: 0.7478 - val_loss: 0.4748 - val_accuracy: 0.7957\n",
      "Epoch 12/30\n",
      "82/82 [==============================] - 32s 393ms/step - loss: 0.5143 - accuracy: 0.7497 - val_loss: 0.4716 - val_accuracy: 0.7988\n",
      "Epoch 13/30\n",
      "82/82 [==============================] - 32s 388ms/step - loss: 0.5057 - accuracy: 0.7612 - val_loss: 0.4652 - val_accuracy: 0.7988\n",
      "Epoch 14/30\n",
      "82/82 [==============================] - 32s 393ms/step - loss: 0.4966 - accuracy: 0.7661 - val_loss: 0.4592 - val_accuracy: 0.8110\n",
      "Epoch 15/30\n",
      "82/82 [==============================] - 32s 394ms/step - loss: 0.4915 - accuracy: 0.7718 - val_loss: 0.4639 - val_accuracy: 0.8110\n",
      "Epoch 16/30\n",
      "82/82 [==============================] - 32s 389ms/step - loss: 0.4816 - accuracy: 0.7764 - val_loss: 0.4665 - val_accuracy: 0.8079\n",
      "Epoch 17/30\n",
      "82/82 [==============================] - 32s 392ms/step - loss: 0.4745 - accuracy: 0.7825 - val_loss: 0.4726 - val_accuracy: 0.7988\n",
      "Epoch 18/30\n",
      "82/82 [==============================] - 32s 396ms/step - loss: 0.4704 - accuracy: 0.7844 - val_loss: 0.4459 - val_accuracy: 0.8079\n",
      "Epoch 19/30\n",
      "82/82 [==============================] - 32s 390ms/step - loss: 0.4999 - accuracy: 0.7871 - val_loss: 0.4501 - val_accuracy: 0.8171\n",
      "Epoch 20/30\n",
      "82/82 [==============================] - 32s 386ms/step - loss: 0.4911 - accuracy: 0.7841 - val_loss: 0.6561 - val_accuracy: 0.6037\n",
      "Epoch 21/30\n",
      "82/82 [==============================] - 32s 392ms/step - loss: 0.4749 - accuracy: 0.7795 - val_loss: 0.4552 - val_accuracy: 0.8018\n",
      "Epoch 22/30\n",
      "82/82 [==============================] - 33s 401ms/step - loss: 0.4460 - accuracy: 0.8096 - val_loss: 0.4560 - val_accuracy: 0.8079\n",
      "Epoch 23/30\n",
      "82/82 [==============================] - 34s 413ms/step - loss: 0.4291 - accuracy: 0.8153 - val_loss: 0.4386 - val_accuracy: 0.8079\n",
      "Epoch 24/30\n",
      "82/82 [==============================] - 33s 397ms/step - loss: 0.4137 - accuracy: 0.8275 - val_loss: 0.4120 - val_accuracy: 0.8354\n",
      "Epoch 25/30\n",
      "82/82 [==============================] - 33s 403ms/step - loss: 0.3980 - accuracy: 0.8401 - val_loss: 0.4247 - val_accuracy: 0.8171\n",
      "Epoch 26/30\n",
      "82/82 [==============================] - 32s 393ms/step - loss: 0.3897 - accuracy: 0.8420 - val_loss: 0.4583 - val_accuracy: 0.8201\n",
      "Epoch 27/30\n",
      "82/82 [==============================] - 32s 390ms/step - loss: 0.4122 - accuracy: 0.8409 - val_loss: 0.4462 - val_accuracy: 0.8079\n",
      "Epoch 28/30\n",
      "82/82 [==============================] - 32s 392ms/step - loss: 0.3497 - accuracy: 0.8623 - val_loss: 0.5106 - val_accuracy: 0.7927\n",
      "Epoch 29/30\n",
      "82/82 [==============================] - 32s 392ms/step - loss: 0.3631 - accuracy: 0.8569 - val_loss: 0.5224 - val_accuracy: 0.7896\n",
      "Epoch 30/30\n",
      "82/82 [==============================] - 32s 396ms/step - loss: 0.3884 - accuracy: 0.8298 - val_loss: 0.5049 - val_accuracy: 0.7805\n"
     ]
    }
   ],
   "source": [
    "# ----- ResNet -----\n",
    "inputs = Input(shape=(96,96,3))\n",
    "x = Conv2D(filters=48, kernel_size=11, activation='relu')(inputs)\n",
    "x = Dropout(0.3)(x)\n",
    "x = MaxPooling2D((3, 3) )(x)\n",
    "x = Conv2D(filters=128, kernel_size=5, activation='relu')(x)\n",
    "x = MaxPooling2D((3, 3) )(x)\n",
    "x = Conv2D(filters=192, kernel_size=3, activation='relu')(x)\n",
    "x = Conv2D(filters=192, kernel_size=3, activation='relu')(x)\n",
    "x = Conv2D(filters=128, kernel_size=3, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "#x = MaxPooling2D((3, 3), strides=(2,2) )(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "\n",
    "outputs = Dense(2, activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "#x = AveragePooling2D(pool_size=2)(x)\n",
    "#x = Conv2D(filters=6, kernel_size=3, activation='relu')(x)\n",
    "#x = AveragePooling2D(pool_size=2)(x)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# ----- Configure model -----\n",
    "model.compile(optimizer=opt.Nadam(learning_rate=0.0002),\n",
    "\tloss='categorical_crossentropy',\n",
    "\tmetrics=['accuracy'])\n",
    "\n",
    "# ----- Train model -----\n",
    "history = model.fit(train, epochs = 30, validation_data= val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 96, 96, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 86, 86, 48)        17472     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 86, 86, 48)        0         \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 28, 28, 48)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 24, 24, 128)       153728    \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 8, 8, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 6, 6, 64)          73792     \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 2, 2, 256)         295168    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 2, 2, 256)         0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 128)               131200    \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 512)               131584    \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 910,850\n",
      "Trainable params: 910,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "82/82 [==============================] - 33s 386ms/step - loss: 0.6887 - accuracy: 0.5639 - val_loss: 0.6809 - val_accuracy: 0.5091\n",
      "Epoch 2/30\n",
      "82/82 [==============================] - 31s 384ms/step - loss: 0.6307 - accuracy: 0.6784 - val_loss: 0.5655 - val_accuracy: 0.7470\n",
      "Epoch 3/30\n",
      "82/82 [==============================] - 32s 384ms/step - loss: 0.5584 - accuracy: 0.7215 - val_loss: 0.5075 - val_accuracy: 0.7896\n",
      "Epoch 4/30\n",
      "82/82 [==============================] - 32s 389ms/step - loss: 0.5366 - accuracy: 0.7413 - val_loss: 0.4900 - val_accuracy: 0.8018\n",
      "Epoch 5/30\n",
      "82/82 [==============================] - 32s 388ms/step - loss: 0.5296 - accuracy: 0.7463 - val_loss: 0.4838 - val_accuracy: 0.7957\n",
      "Epoch 6/30\n",
      "82/82 [==============================] - 32s 396ms/step - loss: 0.5253 - accuracy: 0.7543 - val_loss: 0.4792 - val_accuracy: 0.7927\n",
      "Epoch 7/30\n",
      "82/82 [==============================] - 32s 385ms/step - loss: 0.5230 - accuracy: 0.7543 - val_loss: 0.4764 - val_accuracy: 0.7896\n",
      "Epoch 8/30\n",
      "82/82 [==============================] - 32s 387ms/step - loss: 0.5190 - accuracy: 0.7478 - val_loss: 0.4734 - val_accuracy: 0.7866\n",
      "Epoch 9/30\n",
      "82/82 [==============================] - 32s 386ms/step - loss: 0.5166 - accuracy: 0.7524 - val_loss: 0.4707 - val_accuracy: 0.7866\n",
      "Epoch 10/30\n",
      "82/82 [==============================] - 32s 386ms/step - loss: 0.5162 - accuracy: 0.7531 - val_loss: 0.4690 - val_accuracy: 0.7866\n",
      "Epoch 11/30\n",
      "82/82 [==============================] - 32s 385ms/step - loss: 0.5141 - accuracy: 0.7539 - val_loss: 0.4674 - val_accuracy: 0.7896\n",
      "Epoch 12/30\n",
      "82/82 [==============================] - 33s 402ms/step - loss: 0.5107 - accuracy: 0.7516 - val_loss: 0.4635 - val_accuracy: 0.7927\n",
      "Epoch 13/30\n",
      "82/82 [==============================] - 33s 403ms/step - loss: 0.5093 - accuracy: 0.7543 - val_loss: 0.4632 - val_accuracy: 0.7957\n",
      "Epoch 14/30\n",
      "82/82 [==============================] - 33s 397ms/step - loss: 0.5083 - accuracy: 0.7585 - val_loss: 0.4620 - val_accuracy: 0.7835\n",
      "Epoch 15/30\n",
      "82/82 [==============================] - 34s 419ms/step - loss: 0.5076 - accuracy: 0.7570 - val_loss: 0.4614 - val_accuracy: 0.7927\n",
      "Epoch 16/30\n",
      "82/82 [==============================] - 32s 390ms/step - loss: 0.5047 - accuracy: 0.7558 - val_loss: 0.4596 - val_accuracy: 0.7896\n",
      "Epoch 17/30\n",
      "82/82 [==============================] - 32s 386ms/step - loss: 0.5040 - accuracy: 0.7608 - val_loss: 0.4566 - val_accuracy: 0.7957\n",
      "Epoch 18/30\n",
      "82/82 [==============================] - 32s 384ms/step - loss: 0.5016 - accuracy: 0.7619 - val_loss: 0.4553 - val_accuracy: 0.7927\n",
      "Epoch 19/30\n",
      "82/82 [==============================] - 32s 387ms/step - loss: 0.4977 - accuracy: 0.7623 - val_loss: 0.4537 - val_accuracy: 0.7957\n",
      "Epoch 20/30\n",
      "82/82 [==============================] - 31s 378ms/step - loss: 0.4998 - accuracy: 0.7577 - val_loss: 0.4570 - val_accuracy: 0.7957\n",
      "Epoch 21/30\n",
      "82/82 [==============================] - 31s 378ms/step - loss: 0.4989 - accuracy: 0.7581 - val_loss: 0.4530 - val_accuracy: 0.7988\n",
      "Epoch 22/30\n",
      "82/82 [==============================] - 31s 378ms/step - loss: 0.4955 - accuracy: 0.7623 - val_loss: 0.4541 - val_accuracy: 0.7957\n",
      "Epoch 23/30\n",
      "30/82 [=========>....................] - ETA: 20s - loss: 0.5159 - accuracy: 0.7323"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\chrse\\Desktop\\applied_ML_faelles\\exam\\question_2\\christoffer.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/christoffer.ipynb#X21sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mopt\u001b[39m.\u001b[39mNadam(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.00002\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/christoffer.ipynb#X21sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \tloss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/christoffer.ipynb#X21sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \tmetrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/christoffer.ipynb#X21sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m# ----- Train model -----\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/christoffer.ipynb#X21sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train, epochs \u001b[39m=\u001b[39;49m \u001b[39m30\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m val)\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ----- ResNet -----\n",
    "inputs = Input(shape=(96,96,3))\n",
    "x = Conv2D(filters=48, kernel_size=11, activation='relu')(inputs)\n",
    "x = Dropout(0.3)(x)\n",
    "x = MaxPooling2D((3, 3) )(x)\n",
    "x = Conv2D(filters=128, kernel_size=5, activation='relu')(x)\n",
    "x = MaxPooling2D((3, 3) )(x)\n",
    "x = Conv2D(filters=64, kernel_size=3, activation='relu')(x)\n",
    "x = Conv2D(filters=128, kernel_size=3, activation='relu')(x)\n",
    "x = Conv2D(filters=256, kernel_size=3, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "#x = MaxPooling2D((3, 3), strides=(2,2) )(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "\n",
    "outputs = Dense(2, activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "#x = AveragePooling2D(pool_size=2)(x)\n",
    "#x = Conv2D(filters=6, kernel_size=3, activation='relu')(x)\n",
    "#x = AveragePooling2D(pool_size=2)(x)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# ----- Configure model -----\n",
    "model.compile(optimizer=opt.Nadam(learning_rate=0.00002),\n",
    "\tloss='categorical_crossentropy',\n",
    "\tmetrics=['accuracy'])\n",
    "\n",
    "# ----- Train model -----\n",
    "history = model.fit(train, epochs = 30, validation_data= val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 96, 96, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 86, 86, 48)        17472     \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 86, 86, 48)        0         \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 28, 28, 48)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_36 (Conv2D)          (None, 24, 24, 128)       153728    \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 6, 6, 128)         147584    \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 4, 4, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_39 (Conv2D)          (None, 2, 2, 512)         1180160   \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 2, 2, 512)         0         \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 128)               262272    \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,130,690\n",
      "Trainable params: 2,130,690\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "82/82 [==============================] - 43s 510ms/step - loss: 0.6921 - accuracy: 0.5162 - val_loss: 0.6887 - val_accuracy: 0.7500\n",
      "Epoch 2/30\n",
      "82/82 [==============================] - 41s 497ms/step - loss: 0.6796 - accuracy: 0.5727 - val_loss: 0.6438 - val_accuracy: 0.7683\n",
      "Epoch 3/30\n",
      "82/82 [==============================] - 40s 488ms/step - loss: 0.6115 - accuracy: 0.6818 - val_loss: 0.5424 - val_accuracy: 0.7622\n",
      "Epoch 4/30\n",
      "82/82 [==============================] - 39s 472ms/step - loss: 0.5616 - accuracy: 0.7264 - val_loss: 0.5104 - val_accuracy: 0.7713\n",
      "Epoch 5/30\n",
      "82/82 [==============================] - 39s 474ms/step - loss: 0.5502 - accuracy: 0.7386 - val_loss: 0.4988 - val_accuracy: 0.7744\n",
      "Epoch 6/30\n",
      "82/82 [==============================] - 39s 477ms/step - loss: 0.5358 - accuracy: 0.7425 - val_loss: 0.4830 - val_accuracy: 0.7866\n",
      "Epoch 7/30\n",
      "82/82 [==============================] - 39s 476ms/step - loss: 0.5318 - accuracy: 0.7478 - val_loss: 0.4922 - val_accuracy: 0.7805\n",
      "Epoch 8/30\n",
      "82/82 [==============================] - 40s 488ms/step - loss: 0.5254 - accuracy: 0.7524 - val_loss: 0.4755 - val_accuracy: 0.7866\n",
      "Epoch 9/30\n",
      "82/82 [==============================] - 40s 490ms/step - loss: 0.5223 - accuracy: 0.7593 - val_loss: 0.4730 - val_accuracy: 0.7835\n",
      "Epoch 10/30\n",
      "82/82 [==============================] - 40s 486ms/step - loss: 0.5204 - accuracy: 0.7531 - val_loss: 0.4692 - val_accuracy: 0.7957\n",
      "Epoch 11/30\n",
      "82/82 [==============================] - 40s 493ms/step - loss: 0.5187 - accuracy: 0.7516 - val_loss: 0.4689 - val_accuracy: 0.7988\n",
      "Epoch 12/30\n",
      "82/82 [==============================] - 39s 476ms/step - loss: 0.5192 - accuracy: 0.7554 - val_loss: 0.4702 - val_accuracy: 0.7957\n",
      "Epoch 13/30\n",
      "82/82 [==============================] - 41s 501ms/step - loss: 0.5161 - accuracy: 0.7539 - val_loss: 0.4599 - val_accuracy: 0.7896\n",
      "Epoch 14/30\n",
      "82/82 [==============================] - 40s 488ms/step - loss: 0.5140 - accuracy: 0.7615 - val_loss: 0.4676 - val_accuracy: 0.7835\n",
      "Epoch 15/30\n",
      "82/82 [==============================] - 39s 470ms/step - loss: 0.5141 - accuracy: 0.7581 - val_loss: 0.4639 - val_accuracy: 0.7835\n",
      "Epoch 16/30\n",
      "82/82 [==============================] - 40s 491ms/step - loss: 0.5091 - accuracy: 0.7612 - val_loss: 0.4564 - val_accuracy: 0.7896\n",
      "Epoch 17/30\n",
      "82/82 [==============================] - 40s 488ms/step - loss: 0.5138 - accuracy: 0.7566 - val_loss: 0.4580 - val_accuracy: 0.7896\n",
      "Epoch 18/30\n",
      "82/82 [==============================] - 40s 489ms/step - loss: 0.5111 - accuracy: 0.7581 - val_loss: 0.4579 - val_accuracy: 0.7896\n",
      "Epoch 19/30\n",
      "73/82 [=========================>....] - ETA: 4s - loss: 0.5021 - accuracy: 0.7598"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\chrse\\Desktop\\applied_ML_faelles\\exam\\question_2\\christoffer.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/christoffer.ipynb#X22sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mopt\u001b[39m.\u001b[39mNadam(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.00002\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/christoffer.ipynb#X22sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \tloss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/christoffer.ipynb#X22sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \tmetrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/christoffer.ipynb#X22sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m# ----- Train model -----\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/christoffer.ipynb#X22sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train, epochs \u001b[39m=\u001b[39;49m \u001b[39m30\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m val)\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ----- ResNet -----\n",
    "inputs = Input(shape=(96,96,3))\n",
    "x = Conv2D(filters=48, kernel_size=11, activation='relu')(inputs)\n",
    "x = Dropout(0.3)(x)\n",
    "x = MaxPooling2D((3, 3) )(x)\n",
    "x = Conv2D(filters=128, kernel_size=5, activation='relu')(x)\n",
    "x = MaxPooling2D((3, 3) )(x)\n",
    "x = Conv2D(filters=128, kernel_size=3, activation='relu')(x)\n",
    "x = Conv2D(filters=256, kernel_size=3, activation='relu')(x)\n",
    "x = Conv2D(filters=512, kernel_size=3, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "#x = MaxPooling2D((3, 3), strides=(2,2) )(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "outputs = Dense(2, activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "#x = AveragePooling2D(pool_size=2)(x)\n",
    "#x = Conv2D(filters=6, kernel_size=3, activation='relu')(x)\n",
    "#x = AveragePooling2D(pool_size=2)(x)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# ----- Configure model -----\n",
    "model.compile(optimizer=opt.Nadam(learning_rate=0.00002),\n",
    "\tloss='categorical_crossentropy',\n",
    "\tmetrics=['accuracy'])\n",
    "\n",
    "# ----- Train model -----\n",
    "history = model.fit(train, epochs = 30, validation_data= val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_17 (InputLayer)       [(None, 96, 96, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_74 (Conv2D)          (None, 86, 86, 128)       46592     \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        (None, 86, 86, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_32 (MaxPoolin  (None, 28, 28, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_75 (Conv2D)          (None, 24, 24, 128)       409728    \n",
      "                                                                 \n",
      " max_pooling2d_33 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_76 (Conv2D)          (None, 6, 6, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_77 (Conv2D)          (None, 4, 4, 512)         1180160   \n",
      "                                                                 \n",
      " dropout_50 (Dropout)        (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 128)               1048704   \n",
      "                                                                 \n",
      " dropout_51 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dropout_52 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,005,250\n",
      "Trainable params: 3,005,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "82/82 [==============================] - 88s 1s/step - loss: 3.3795 - accuracy: 0.5090 - val_loss: 3.2626 - val_accuracy: 0.5579\n",
      "Epoch 2/100\n",
      "82/82 [==============================] - 86s 1s/step - loss: 3.1565 - accuracy: 0.5696 - val_loss: 3.0271 - val_accuracy: 0.7683\n",
      "Epoch 3/100\n",
      "82/82 [==============================] - 87s 1s/step - loss: 2.9257 - accuracy: 0.6665 - val_loss: 2.7727 - val_accuracy: 0.7530\n",
      "Epoch 4/100\n",
      "82/82 [==============================] - 89s 1s/step - loss: 2.7266 - accuracy: 0.7180 - val_loss: 2.6081 - val_accuracy: 0.7683\n",
      "Epoch 5/100\n",
      "82/82 [==============================] - 88s 1s/step - loss: 2.5651 - accuracy: 0.7394 - val_loss: 2.4729 - val_accuracy: 0.7713\n",
      "Epoch 6/100\n",
      "82/82 [==============================] - 89s 1s/step - loss: 2.4476 - accuracy: 0.7375 - val_loss: 2.3572 - val_accuracy: 0.7744\n",
      "Epoch 7/100\n",
      "82/82 [==============================] - 89s 1s/step - loss: 2.3471 - accuracy: 0.7451 - val_loss: 2.2655 - val_accuracy: 0.7835\n",
      "Epoch 8/100\n",
      "82/82 [==============================] - 89s 1s/step - loss: 2.2500 - accuracy: 0.7478 - val_loss: 2.1622 - val_accuracy: 0.7927\n",
      "Epoch 9/100\n",
      "82/82 [==============================] - 89s 1s/step - loss: 2.1672 - accuracy: 0.7501 - val_loss: 2.0837 - val_accuracy: 0.7866\n",
      "Epoch 10/100\n",
      "82/82 [==============================] - 88s 1s/step - loss: 2.0977 - accuracy: 0.7493 - val_loss: 2.0173 - val_accuracy: 0.7927\n",
      "Epoch 11/100\n",
      "82/82 [==============================] - 87s 1s/step - loss: 2.0279 - accuracy: 0.7528 - val_loss: 1.9475 - val_accuracy: 0.7957\n",
      "Epoch 12/100\n",
      "82/82 [==============================] - 87s 1s/step - loss: 1.9702 - accuracy: 0.7531 - val_loss: 1.8924 - val_accuracy: 0.7927\n",
      "Epoch 13/100\n",
      "82/82 [==============================] - 87s 1s/step - loss: 1.9086 - accuracy: 0.7512 - val_loss: 1.8439 - val_accuracy: 0.7957\n",
      "Epoch 14/100\n",
      "82/82 [==============================] - 87s 1s/step - loss: 1.8589 - accuracy: 0.7570 - val_loss: 1.7916 - val_accuracy: 0.7866\n",
      "Epoch 15/100\n",
      "82/82 [==============================] - 86s 1s/step - loss: 1.8107 - accuracy: 0.7520 - val_loss: 1.7520 - val_accuracy: 0.7866\n",
      "Epoch 16/100\n",
      "82/82 [==============================] - 86s 1s/step - loss: 1.7706 - accuracy: 0.7585 - val_loss: 1.7021 - val_accuracy: 0.7927\n",
      "Epoch 17/100\n",
      "82/82 [==============================] - 87s 1s/step - loss: 1.7293 - accuracy: 0.7528 - val_loss: 1.6704 - val_accuracy: 0.7927\n",
      "Epoch 18/100\n",
      "82/82 [==============================] - 87s 1s/step - loss: 1.6877 - accuracy: 0.7581 - val_loss: 1.6244 - val_accuracy: 0.7927\n",
      "Epoch 19/100\n",
      "82/82 [==============================] - 87s 1s/step - loss: 1.6512 - accuracy: 0.7612 - val_loss: 1.5886 - val_accuracy: 0.7927\n",
      "Epoch 20/100\n",
      "82/82 [==============================] - 87s 1s/step - loss: 1.6206 - accuracy: 0.7573 - val_loss: 1.5619 - val_accuracy: 0.7927\n",
      "Epoch 21/100\n",
      "82/82 [==============================] - 87s 1s/step - loss: 1.5852 - accuracy: 0.7623 - val_loss: 1.5290 - val_accuracy: 0.7866\n",
      "Epoch 22/100\n",
      "82/82 [==============================] - 88s 1s/step - loss: 1.5524 - accuracy: 0.7615 - val_loss: 1.4906 - val_accuracy: 0.7988\n",
      "Epoch 23/100\n",
      "82/82 [==============================] - 87s 1s/step - loss: 1.5208 - accuracy: 0.7589 - val_loss: 1.4641 - val_accuracy: 0.7988\n",
      "Epoch 24/100\n",
      "82/82 [==============================] - 88s 1s/step - loss: 1.4935 - accuracy: 0.7631 - val_loss: 1.4398 - val_accuracy: 0.7927\n",
      "Epoch 25/100\n",
      "82/82 [==============================] - 87s 1s/step - loss: 1.4642 - accuracy: 0.7631 - val_loss: 1.4121 - val_accuracy: 0.7957\n",
      "Epoch 26/100\n",
      "82/82 [==============================] - 87s 1s/step - loss: 1.4390 - accuracy: 0.7646 - val_loss: 1.3826 - val_accuracy: 0.7957\n",
      "Epoch 27/100\n",
      "82/82 [==============================] - 87s 1s/step - loss: 1.4117 - accuracy: 0.7654 - val_loss: 1.3613 - val_accuracy: 0.7927\n",
      "Epoch 28/100\n",
      "82/82 [==============================] - 87s 1s/step - loss: 1.3876 - accuracy: 0.7600 - val_loss: 1.3352 - val_accuracy: 0.7988\n",
      "Epoch 29/100\n",
      "82/82 [==============================] - 87s 1s/step - loss: 1.3627 - accuracy: 0.7688 - val_loss: 1.3069 - val_accuracy: 0.7957\n",
      "Epoch 30/100\n",
      "82/82 [==============================] - 87s 1s/step - loss: 1.3385 - accuracy: 0.7627 - val_loss: 1.2929 - val_accuracy: 0.7988\n",
      "Epoch 31/100\n",
      "82/82 [==============================] - 87s 1s/step - loss: 1.3160 - accuracy: 0.7696 - val_loss: 1.2665 - val_accuracy: 0.7988\n",
      "Epoch 32/100\n",
      "82/82 [==============================] - 87s 1s/step - loss: 1.2969 - accuracy: 0.7669 - val_loss: 1.2513 - val_accuracy: 0.7988\n",
      "Epoch 33/100\n",
      "82/82 [==============================] - 88s 1s/step - loss: 1.2686 - accuracy: 0.7726 - val_loss: 1.2228 - val_accuracy: 0.8018\n",
      "Epoch 34/100\n",
      "82/82 [==============================] - 87s 1s/step - loss: 1.2495 - accuracy: 0.7699 - val_loss: 1.2074 - val_accuracy: 0.8018\n",
      "Epoch 35/100\n",
      "82/82 [==============================] - 88s 1s/step - loss: 1.2305 - accuracy: 0.7722 - val_loss: 1.1831 - val_accuracy: 0.8049\n",
      "Epoch 36/100\n",
      "82/82 [==============================] - 88s 1s/step - loss: 1.2148 - accuracy: 0.7715 - val_loss: 1.1720 - val_accuracy: 0.7927\n",
      "Epoch 37/100\n",
      "82/82 [==============================] - 88s 1s/step - loss: 1.1915 - accuracy: 0.7718 - val_loss: 1.1478 - val_accuracy: 0.8049\n",
      "Epoch 38/100\n",
      "82/82 [==============================] - 88s 1s/step - loss: 1.1701 - accuracy: 0.7776 - val_loss: 1.1288 - val_accuracy: 0.7957\n",
      "Epoch 39/100\n",
      "82/82 [==============================] - 89s 1s/step - loss: 1.1487 - accuracy: 0.7757 - val_loss: 1.1108 - val_accuracy: 0.7927\n",
      "Epoch 40/100\n",
      "82/82 [==============================] - 87s 1s/step - loss: 1.1318 - accuracy: 0.7802 - val_loss: 1.0923 - val_accuracy: 0.7957\n",
      "Epoch 41/100\n",
      "82/82 [==============================] - 87s 1s/step - loss: 1.1160 - accuracy: 0.7791 - val_loss: 1.0736 - val_accuracy: 0.8018\n",
      "Epoch 42/100\n",
      "82/82 [==============================] - 88s 1s/step - loss: 1.0950 - accuracy: 0.7787 - val_loss: 1.0576 - val_accuracy: 0.8079\n",
      "Epoch 43/100\n",
      "82/82 [==============================] - 87s 1s/step - loss: 1.0796 - accuracy: 0.7825 - val_loss: 1.0422 - val_accuracy: 0.8018\n",
      "Epoch 44/100\n",
      "82/82 [==============================] - 87s 1s/step - loss: 1.0616 - accuracy: 0.7810 - val_loss: 1.0244 - val_accuracy: 0.8079\n",
      "Epoch 45/100\n",
      "82/82 [==============================] - 88s 1s/step - loss: 1.0380 - accuracy: 0.7844 - val_loss: 1.0032 - val_accuracy: 0.8079\n",
      "Epoch 46/100\n",
      "82/82 [==============================] - 87s 1s/step - loss: 1.0289 - accuracy: 0.7882 - val_loss: 0.9942 - val_accuracy: 0.8140\n",
      "Epoch 47/100\n",
      "82/82 [==============================] - 87s 1s/step - loss: 1.0078 - accuracy: 0.7928 - val_loss: 0.9796 - val_accuracy: 0.8140\n",
      "Epoch 48/100\n",
      "82/82 [==============================] - 87s 1s/step - loss: 0.9962 - accuracy: 0.7902 - val_loss: 0.9622 - val_accuracy: 0.8110\n",
      "Epoch 49/100\n",
      "82/82 [==============================] - 88s 1s/step - loss: 0.9836 - accuracy: 0.7913 - val_loss: 0.9424 - val_accuracy: 0.8171\n",
      "Epoch 50/100\n",
      "82/82 [==============================] - 87s 1s/step - loss: 0.9599 - accuracy: 0.7947 - val_loss: 0.9390 - val_accuracy: 0.8079\n",
      "Epoch 51/100\n",
      "82/82 [==============================] - 87s 1s/step - loss: 0.9534 - accuracy: 0.7955 - val_loss: 0.9173 - val_accuracy: 0.8110\n",
      "Epoch 52/100\n",
      "82/82 [==============================] - 87s 1s/step - loss: 0.9384 - accuracy: 0.7982 - val_loss: 0.9108 - val_accuracy: 0.8201\n",
      "Epoch 53/100\n",
      "82/82 [==============================] - 87s 1s/step - loss: 0.9216 - accuracy: 0.7997 - val_loss: 0.8961 - val_accuracy: 0.8140\n",
      "Epoch 54/100\n",
      "82/82 [==============================] - 87s 1s/step - loss: 0.9086 - accuracy: 0.8024 - val_loss: 0.8840 - val_accuracy: 0.8140\n",
      "Epoch 55/100\n",
      "82/82 [==============================] - 87s 1s/step - loss: 0.8964 - accuracy: 0.7982 - val_loss: 0.8790 - val_accuracy: 0.8110\n",
      "Epoch 56/100\n",
      "82/82 [==============================] - 87s 1s/step - loss: 0.8817 - accuracy: 0.8047 - val_loss: 0.8685 - val_accuracy: 0.8110\n",
      "Epoch 57/100\n",
      "82/82 [==============================] - 87s 1s/step - loss: 0.8710 - accuracy: 0.8073 - val_loss: 0.8478 - val_accuracy: 0.8140\n",
      "Epoch 58/100\n",
      "82/82 [==============================] - 89s 1s/step - loss: 0.8586 - accuracy: 0.8104 - val_loss: 0.8388 - val_accuracy: 0.8110\n",
      "Epoch 59/100\n",
      "82/82 [==============================] - 89s 1s/step - loss: 0.8510 - accuracy: 0.8081 - val_loss: 0.8265 - val_accuracy: 0.8293\n",
      "Epoch 60/100\n",
      "82/82 [==============================] - 86s 1s/step - loss: 0.8354 - accuracy: 0.8157 - val_loss: 0.8207 - val_accuracy: 0.8140\n",
      "Epoch 61/100\n",
      "82/82 [==============================] - 87s 1s/step - loss: 0.8218 - accuracy: 0.8161 - val_loss: 0.8119 - val_accuracy: 0.8171\n",
      "Epoch 62/100\n",
      "82/82 [==============================] - 87s 1s/step - loss: 0.8130 - accuracy: 0.8089 - val_loss: 0.8025 - val_accuracy: 0.8018\n",
      "Epoch 63/100\n",
      "82/82 [==============================] - 87s 1s/step - loss: 0.7962 - accuracy: 0.8192 - val_loss: 0.7928 - val_accuracy: 0.8079\n",
      "Epoch 64/100\n",
      "82/82 [==============================] - 87s 1s/step - loss: 0.7902 - accuracy: 0.8218 - val_loss: 0.7915 - val_accuracy: 0.8110\n",
      "Epoch 65/100\n",
      "82/82 [==============================] - 88s 1s/step - loss: 0.7763 - accuracy: 0.8195 - val_loss: 0.7779 - val_accuracy: 0.8049\n",
      "Epoch 66/100\n",
      "82/82 [==============================] - 87s 1s/step - loss: 0.7722 - accuracy: 0.8222 - val_loss: 0.7654 - val_accuracy: 0.8140\n",
      "Epoch 67/100\n",
      "82/82 [==============================] - 87s 1s/step - loss: 0.7579 - accuracy: 0.8237 - val_loss: 0.7686 - val_accuracy: 0.8049\n",
      "Epoch 68/100\n",
      "82/82 [==============================] - 87s 1s/step - loss: 0.7509 - accuracy: 0.8275 - val_loss: 0.7593 - val_accuracy: 0.8018\n",
      "Epoch 69/100\n",
      "82/82 [==============================] - 88s 1s/step - loss: 0.7394 - accuracy: 0.8325 - val_loss: 0.7516 - val_accuracy: 0.7988\n",
      "Epoch 70/100\n",
      "82/82 [==============================] - 88s 1s/step - loss: 0.7263 - accuracy: 0.8340 - val_loss: 0.7390 - val_accuracy: 0.7927\n",
      "Epoch 71/100\n",
      "82/82 [==============================] - 88s 1s/step - loss: 0.7182 - accuracy: 0.8337 - val_loss: 0.7436 - val_accuracy: 0.7988\n",
      "Epoch 72/100\n",
      "82/82 [==============================] - 88s 1s/step - loss: 0.7082 - accuracy: 0.8344 - val_loss: 0.7287 - val_accuracy: 0.7957\n",
      "Epoch 73/100\n",
      "82/82 [==============================] - 88s 1s/step - loss: 0.7014 - accuracy: 0.8348 - val_loss: 0.7241 - val_accuracy: 0.8049\n",
      "Epoch 74/100\n",
      "82/82 [==============================] - 88s 1s/step - loss: 0.6882 - accuracy: 0.8390 - val_loss: 0.7200 - val_accuracy: 0.7988\n",
      "Epoch 75/100\n",
      "82/82 [==============================] - 88s 1s/step - loss: 0.6821 - accuracy: 0.8394 - val_loss: 0.7158 - val_accuracy: 0.7957\n",
      "Epoch 76/100\n",
      "47/82 [================>.............] - ETA: 37s - loss: 0.6917 - accuracy: 0.8344"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\chrse\\Desktop\\applied_ML_faelles\\exam\\question_2\\christoffer.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/christoffer.ipynb#X24sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mopt\u001b[39m.\u001b[39mNadam(learning_rate\u001b[39m=\u001b[39m\u001b[39m0.00002\u001b[39m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/christoffer.ipynb#X24sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \tloss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/christoffer.ipynb#X24sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \tmetrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/christoffer.ipynb#X24sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# ----- Train model -----\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/christoffer.ipynb#X24sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train, epochs \u001b[39m=\u001b[39;49m \u001b[39m100\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m val)\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ----- ResNet -----\n",
    "inputs = Input(shape=(96,96,3))\n",
    "x = Conv2D(filters=128, kernel_size=11, activation='relu')(inputs)\n",
    "x = Dropout(0.3)(x)\n",
    "x = MaxPooling2D((3, 3) )(x)\n",
    "x = Conv2D(filters=128, kernel_size=5, activation='relu')(x)\n",
    "x = MaxPooling2D((3, 3) )(x)\n",
    "x = Conv2D(filters=256, kernel_size=3, activation='relu')(x)\n",
    "x = Conv2D(filters=512, kernel_size=3, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "#x = MaxPooling2D((3, 3), strides=(2,2) )(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu', kernel_regularizer=reg.L2(0.006))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(128, activation='relu', kernel_regularizer=reg.L2(0.006))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation='relu', kernel_regularizer=reg.L2(0.006))(x)\n",
    "\n",
    "outputs = Dense(2, activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "#x = AveragePooling2D(pool_size=2)(x)\n",
    "#x = Conv2D(filters=6, kernel_size=3, activation='relu')(x)\n",
    "#x = AveragePooling2D(pool_size=2)(x)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# ----- Configure model -----\n",
    "model.compile(optimizer=opt.Nadam(learning_rate=0.00002),\n",
    "\tloss='categorical_crossentropy',\n",
    "\tmetrics=['accuracy'])\n",
    "\n",
    "# ----- Train model -----\n",
    "history = model.fit(train, epochs = 100, validation_data= val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- ResNet -----\n",
    "inputs = Input(shape=(96,96,3))\n",
    "x = Conv2D(filters=48, kernel_size=11, activation='relu')(inputs)\n",
    "x = Dropout(0.3)(x)\n",
    "x = MaxPooling2D((3, 3) )(x)\n",
    "x = Conv2D(filters=128, kernel_size=5, activation='relu')(x)\n",
    "x = MaxPooling2D((3, 3) )(x)\n",
    "x = Conv2D(filters=128, kernel_size=3, activation='relu')(x)\n",
    "x = Conv2D(filters=256, kernel_size=3, activation='relu')(x)\n",
    "x = Conv2D(filters=512, kernel_size=3, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "#x = MaxPooling2D((3, 3), strides=(2,2) )(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "outputs = Dense(2, activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "#x = AveragePooling2D(pool_size=2)(x)\n",
    "#x = Conv2D(filters=6, kernel_size=3, activation='relu')(x)\n",
    "#x = AveragePooling2D(pool_size=2)(x)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# ----- Configure model -----\n",
    "model.compile(optimizer=opt.Nadam(learning_rate=0.00002),\n",
    "\tloss='categorical_crossentropy',\n",
    "\tmetrics=['accuracy'])\n",
    "\n",
    "# ----- Train model -----\n",
    "history = model.fit(train, epochs = 30, validation_data= val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- ResNet -----\n",
    "inputs = Input(shape=(96,96,3))\n",
    "x = Conv2D(filters=48, kernel_size=11, activation='relu')(inputs)\n",
    "x = Dropout(0.3)(x)\n",
    "x = MaxPooling2D((3, 3) )(x)\n",
    "x = Conv2D(filters=128, kernel_size=5, activation='relu')(x)\n",
    "x = MaxPooling2D((3, 3) )(x)\n",
    "x = Conv2D(filters=192, kernel_size=3, activation='relu')(x)\n",
    "x = Conv2D(filters=192, kernel_size=3, activation='relu')(x)\n",
    "x = Conv2D(filters=128, kernel_size=3, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "#x = MaxPooling2D((3, 3), strides=(2,2) )(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "\n",
    "outputs = Dense(2, activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "#x = AveragePooling2D(pool_size=2)(x)\n",
    "#x = Conv2D(filters=6, kernel_size=3, activation='relu')(x)\n",
    "#x = AveragePooling2D(pool_size=2)(x)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# ----- Configure model -----\n",
    "model.compile(optimizer=opt.Nadam(learning_rate=0.0002),\n",
    "\tloss='categorical_crossentropy',\n",
    "\tmetrics=['accuracy'])\n",
    "\n",
    "# ----- Train model -----\n",
    "history = model.fit(train, epochs = 30, validation_data= val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 96, 96, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 86, 86, 48)        17472     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 86, 86, 48)        0         \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 28, 28, 48)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 24, 24, 128)       153728    \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 6, 6, 192)         221376    \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 4, 4, 192)         331968    \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (None, 2, 2, 128)         221312    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2, 2, 128)         0         \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,340,354\n",
      "Trainable params: 1,340,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "82/82 [==============================] - 33s 389ms/step - loss: 33.2988 - accuracy: 0.5372 - val_loss: 19.4833 - val_accuracy: 0.6402\n",
      "Epoch 2/20\n",
      "82/82 [==============================] - 32s 387ms/step - loss: 10.6060 - accuracy: 0.5582 - val_loss: 3.9079 - val_accuracy: 0.4451\n",
      "Epoch 3/20\n",
      "82/82 [==============================] - 32s 386ms/step - loss: 1.6551 - accuracy: 0.5406 - val_loss: 0.8306 - val_accuracy: 0.4451\n",
      "Epoch 4/20\n",
      "82/82 [==============================] - 31s 384ms/step - loss: 0.8231 - accuracy: 0.4884 - val_loss: 0.8193 - val_accuracy: 0.4451\n",
      "Epoch 5/20\n",
      "82/82 [==============================] - 32s 394ms/step - loss: 0.8184 - accuracy: 0.4815 - val_loss: 0.8168 - val_accuracy: 0.4451\n",
      "Epoch 6/20\n",
      "82/82 [==============================] - 32s 395ms/step - loss: 0.8167 - accuracy: 0.4838 - val_loss: 0.8155 - val_accuracy: 0.5549\n",
      "Epoch 7/20\n",
      "82/82 [==============================] - 32s 394ms/step - loss: 0.8155 - accuracy: 0.4876 - val_loss: 0.8144 - val_accuracy: 0.5549\n",
      "Epoch 8/20\n",
      "82/82 [==============================] - 32s 391ms/step - loss: 0.8146 - accuracy: 0.4891 - val_loss: 0.8135 - val_accuracy: 0.5549\n",
      "Epoch 9/20\n",
      "82/82 [==============================] - 32s 391ms/step - loss: 0.8135 - accuracy: 0.4861 - val_loss: 0.8125 - val_accuracy: 0.5549\n",
      "Epoch 10/20\n",
      "82/82 [==============================] - 32s 389ms/step - loss: 0.8125 - accuracy: 0.4887 - val_loss: 0.8116 - val_accuracy: 0.4451\n",
      "Epoch 11/20\n",
      "82/82 [==============================] - 32s 388ms/step - loss: 0.8115 - accuracy: 0.4826 - val_loss: 0.8105 - val_accuracy: 0.5549\n",
      "Epoch 12/20\n",
      "82/82 [==============================] - 34s 418ms/step - loss: 0.8104 - accuracy: 0.4884 - val_loss: 0.8095 - val_accuracy: 0.5549\n",
      "Epoch 13/20\n",
      "82/82 [==============================] - 34s 411ms/step - loss: 0.8094 - accuracy: 0.4891 - val_loss: 0.8085 - val_accuracy: 0.5549\n",
      "Epoch 14/20\n",
      "82/82 [==============================] - 34s 416ms/step - loss: 0.8084 - accuracy: 0.4830 - val_loss: 0.8075 - val_accuracy: 0.5549\n",
      "Epoch 15/20\n",
      "82/82 [==============================] - 33s 404ms/step - loss: 0.8074 - accuracy: 0.4861 - val_loss: 0.8065 - val_accuracy: 0.5549\n",
      "Epoch 16/20\n",
      "82/82 [==============================] - 31s 381ms/step - loss: 0.8064 - accuracy: 0.4884 - val_loss: 0.8056 - val_accuracy: 0.5549\n",
      "Epoch 17/20\n",
      "82/82 [==============================] - 32s 388ms/step - loss: 0.8055 - accuracy: 0.4819 - val_loss: 0.8046 - val_accuracy: 0.5549\n",
      "Epoch 18/20\n",
      "82/82 [==============================] - 31s 382ms/step - loss: 0.8045 - accuracy: 0.4865 - val_loss: 0.8036 - val_accuracy: 0.5549\n",
      "Epoch 19/20\n",
      "82/82 [==============================] - 32s 389ms/step - loss: 0.8036 - accuracy: 0.4861 - val_loss: 0.8027 - val_accuracy: 0.5549\n",
      "Epoch 20/20\n",
      "82/82 [==============================] - 31s 379ms/step - loss: 0.8026 - accuracy: 0.4796 - val_loss: 0.8018 - val_accuracy: 0.5549\n"
     ]
    }
   ],
   "source": [
    "# ----- ResNet -----\n",
    "inputs = Input(shape=(96,96,3))\n",
    "x = Conv2D(filters=48, kernel_size=11, activation='relu')(inputs)\n",
    "x = Dropout(0.3)(x)\n",
    "x = MaxPooling2D((3, 3) )(x)\n",
    "x = Conv2D(filters=128, kernel_size=5, activation='relu', kernel_regularizer=reg.L1(0.006))(x)\n",
    "x = MaxPooling2D((3, 3) )(x)\n",
    "x = Conv2D(filters=192, kernel_size=3, activation='relu', kernel_regularizer=reg.L1(0.006))(x)\n",
    "x = Conv2D(filters=192, kernel_size=3, activation='relu',)(x)\n",
    "x = Conv2D(filters=128, kernel_size=3, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "#x = MaxPooling2D((3, 3), strides=(2,2) )(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "outputs = Dense(2, activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "#x = AveragePooling2D(pool_size=2)(x)\n",
    "#x = Conv2D(filters=6, kernel_size=3, activation='relu')(x)\n",
    "#x = AveragePooling2D(pool_size=2)(x)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# ----- Configure model -----\n",
    "model.compile(optimizer=opt.Nadam(learning_rate=0.0002),\n",
    "\tloss='categorical_crossentropy',\n",
    "\tmetrics=['accuracy'])\n",
    "\n",
    "# ----- Train model -----\n",
    "history = model.fit(train, epochs = 20, validation_data= val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 96, 96, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 86, 86, 48)        17472     \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 28, 28, 48)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_36 (Conv2D)          (None, 24, 24, 128)       153728    \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 8, 8, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 6, 6, 192)         221376    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 6, 6, 192)         0         \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 4, 4, 192)         331968    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 4, 4, 192)         0         \n",
      "                                                                 \n",
      " conv2d_39 (Conv2D)          (None, 2, 2, 128)         221312    \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 2, 2, 128)         0         \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,340,354\n",
      "Trainable params: 1,340,354\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "82/82 [==============================] - 26s 305ms/step - loss: 11.7661 - accuracy: 0.5174 - val_loss: 6.3413 - val_accuracy: 0.6311\n",
      "Epoch 2/20\n",
      "82/82 [==============================] - 26s 322ms/step - loss: 3.1978 - accuracy: 0.5712 - val_loss: 1.1032 - val_accuracy: 0.4451\n",
      "Epoch 3/20\n",
      "82/82 [==============================] - 26s 320ms/step - loss: 0.7950 - accuracy: 0.4968 - val_loss: 0.7471 - val_accuracy: 0.4451\n",
      "Epoch 4/20\n",
      "82/82 [==============================] - 25s 308ms/step - loss: 0.7452 - accuracy: 0.5055 - val_loss: 0.7432 - val_accuracy: 0.6463\n",
      "Epoch 5/20\n",
      "82/82 [==============================] - 25s 305ms/step - loss: 0.7439 - accuracy: 0.5292 - val_loss: 0.7480 - val_accuracy: 0.4451\n",
      "Epoch 6/20\n",
      "82/82 [==============================] - 25s 305ms/step - loss: 0.7455 - accuracy: 0.5044 - val_loss: 0.7452 - val_accuracy: 0.4451\n",
      "Epoch 7/20\n",
      "82/82 [==============================] - 25s 309ms/step - loss: 0.7466 - accuracy: 0.5235 - val_loss: 0.7467 - val_accuracy: 0.4451\n",
      "Epoch 8/20\n",
      "82/82 [==============================] - 25s 310ms/step - loss: 0.7442 - accuracy: 0.5048 - val_loss: 0.7415 - val_accuracy: 0.5549\n",
      "Epoch 9/20\n",
      "82/82 [==============================] - 27s 326ms/step - loss: 0.7428 - accuracy: 0.4914 - val_loss: 0.7409 - val_accuracy: 0.5549\n",
      "Epoch 10/20\n",
      "82/82 [==============================] - 25s 307ms/step - loss: 0.7420 - accuracy: 0.5021 - val_loss: 0.7407 - val_accuracy: 0.5549\n",
      "Epoch 11/20\n",
      "82/82 [==============================] - 26s 319ms/step - loss: 0.7416 - accuracy: 0.5040 - val_loss: 0.7392 - val_accuracy: 0.5549\n",
      "Epoch 12/20\n",
      "82/82 [==============================] - 25s 307ms/step - loss: 0.7364 - accuracy: 0.5517 - val_loss: 0.7536 - val_accuracy: 0.4451\n",
      "Epoch 13/20\n",
      "82/82 [==============================] - 25s 305ms/step - loss: 0.7416 - accuracy: 0.5189 - val_loss: 0.7434 - val_accuracy: 0.4451\n",
      "Epoch 14/20\n",
      "82/82 [==============================] - 25s 305ms/step - loss: 0.7381 - accuracy: 0.5074 - val_loss: 0.7500 - val_accuracy: 0.4451\n",
      "Epoch 15/20\n",
      "82/82 [==============================] - 25s 305ms/step - loss: 0.7431 - accuracy: 0.4987 - val_loss: 0.7418 - val_accuracy: 0.4451\n",
      "Epoch 16/20\n",
      "82/82 [==============================] - 25s 304ms/step - loss: 0.7408 - accuracy: 0.4819 - val_loss: 0.7402 - val_accuracy: 0.4451\n",
      "Epoch 17/20\n",
      "82/82 [==============================] - 25s 305ms/step - loss: 0.7411 - accuracy: 0.5029 - val_loss: 0.7391 - val_accuracy: 0.4482\n",
      "Epoch 18/20\n",
      "82/82 [==============================] - 25s 300ms/step - loss: 0.7364 - accuracy: 0.5319 - val_loss: 0.7436 - val_accuracy: 0.4451\n",
      "Epoch 19/20\n",
      "82/82 [==============================] - 25s 304ms/step - loss: 0.7358 - accuracy: 0.5292 - val_loss: 0.7423 - val_accuracy: 0.4451\n",
      "Epoch 20/20\n",
      "82/82 [==============================] - 25s 299ms/step - loss: 0.7398 - accuracy: 0.5315 - val_loss: 0.7123 - val_accuracy: 0.5915\n"
     ]
    }
   ],
   "source": [
    "# ----- ResNet -----\n",
    "inputs = Input(shape=(96,96,3))\n",
    "x = Conv2D(filters=48, kernel_size=11, activation='relu')(inputs)\n",
    "x = MaxPooling2D((3, 3) )(x)\n",
    "x = Conv2D(filters=128, kernel_size=5, activation='relu', kernel_regularizer=reg.L1(0.006))(x)\n",
    "x = MaxPooling2D((3, 3) )(x)\n",
    "x = Conv2D(filters=192, kernel_size=3, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Conv2D(filters=192, kernel_size=3, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Conv2D(filters=128, kernel_size=3, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "#x = MaxPooling2D((3, 3), strides=(2,2) )(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "outputs = Dense(2, activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "#x = AveragePooling2D(pool_size=2)(x)\n",
    "#x = Conv2D(filters=6, kernel_size=3, activation='relu')(x)\n",
    "#x = AveragePooling2D(pool_size=2)(x)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# ----- Configure model -----\n",
    "model.compile(optimizer=opt.Nadam(learning_rate=0.0002),\n",
    "\tloss='categorical_crossentropy',\n",
    "\tmetrics=['accuracy'])\n",
    "\n",
    "# ----- Train model -----\n",
    "history = model.fit(train, epochs = 20, validation_data= val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "\n",
    "\n",
    "# Plot 1 values\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "\n",
    "\n",
    "# Plot 2 values\n",
    "acc_values = history_dict['accuracy']\n",
    "val_values = history_dict['val_accuracy']\n",
    "\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "\n",
    "# Plot 1\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs, loss_values, 'r', label='Training loss') # 'bo' is for blue dot, 'b' is for solid blue line\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "# Plot 2\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs, acc_values, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_values, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
      "WARNING:matplotlib.legend:No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_hist(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9f103ef9cbf49316bd58993216c58d1294ab2db4d797a0ed3c394268b3d025fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
