{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# ----- Tensorflow -----\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from keras import regularizers as reg\n",
    "from keras import optimizers\n",
    "from keras.models import Model, load_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers import Input, Dropout, Dense, Conv2D, MaxPooling2D, Flatten, Concatenate, AveragePooling2D, Rescaling\n",
    "\n",
    "# ----- Utility functions -----\n",
    "from utils import load_data, plot_hist"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'C:/Users/chrse/Desktop/project_aml'\n",
    "BATCH_SIZE = 32\n",
    "train, test, val = load_data(data_dir, perc=1, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architectures\n",
    "Before we begin building complex architectures for the CNN model, we must establish a baseline classifier which we will attempt to beat. This common-sense baseline will tell us if we are moving in the right direction. In our case, we can choose a simple random classifier with a threshold of 0.5 since we have a binary classification problem where half of the samples belong to class A and the remaining 50% belong to class B. We could also specify a 'simple' machine learning algorithm as a baseline, but although we do not do this explicitly, we will aim to beat the trained models in question 1 as CNNs has some properties that make them superior to non-deep learning algorithms and feedforward neural networks (Chollet, 2021).\n",
    "\n",
    "At this point, the first thing we want to achieve is statistical power, i.e. to cross the threshold of our baseline classifier by developing a small model. To do so, we focus on parameters such as the loss function, batch_size, learning rate, etc. Due to the way we represent the labels, we will use the softmax activation and the loss function categorical cross entropy rather than sigmoid and binary cross entropy, however, this will not change the results of our models.\n",
    "\n",
    "Kommentar: Husk arkitektur (stÃ¸rrelse/bredde) og default valg af optimizer (adam) + valgte parametre = default settings + FLOW CHART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 96, 96, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 94, 94, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 47, 47, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 45, 45, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 22, 22, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 20, 20, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 10, 10, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 4, 4, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 2, 2, 256)         590080    \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 2050      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 980,546\n",
      "Trainable params: 980,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "82/82 [==============================] - 18s 212ms/step - loss: 0.6591 - accuracy: 0.5979 - val_loss: 0.4737 - val_accuracy: 0.8018\n",
      "Epoch 2/30\n",
      "82/82 [==============================] - 18s 217ms/step - loss: 0.5768 - accuracy: 0.7272 - val_loss: 0.4294 - val_accuracy: 0.8079\n",
      "Epoch 3/30\n",
      "82/82 [==============================] - 18s 223ms/step - loss: 0.5278 - accuracy: 0.7467 - val_loss: 0.4707 - val_accuracy: 0.7683\n",
      "Epoch 4/30\n",
      " 5/82 [>.............................] - ETA: 16s - loss: 0.5518 - accuracy: 0.7312"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\chrse\\Desktop\\applied_ML_faelles\\exam\\question_2\\faelles.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/faelles.ipynb#X11sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mopt,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/faelles.ipynb#X11sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \t\t\t  loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/faelles.ipynb#X11sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \t\t\t  metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/faelles.ipynb#X11sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# ----- Train model -----\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/faelles.ipynb#X11sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/faelles.ipynb#X11sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \t\t\t\t\tepochs \u001b[39m=\u001b[39;49m \u001b[39m30\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/faelles.ipynb#X11sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \t\t\t\t\tvalidation_data\u001b[39m=\u001b[39;49m val)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/faelles.ipynb#X11sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# ----- Plot performance -----\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/faelles.ipynb#X11sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m plot_hist(history)\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ----- Relatively Simple Convnet from DLPR -----\n",
    "inputs = Input(shape=(96, 96, 3))\n",
    "x = Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "x = Flatten()(x)\n",
    "outputs = Dense(2, activation=\"softmax\")(x)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# ----- Model summary -----\n",
    "model.summary()\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "# ----- Configure model -----\n",
    "model.compile(optimizer=opt,\n",
    "\t\t\t  loss='categorical_crossentropy',\n",
    "\t\t\t  metrics=['accuracy'])\n",
    "\n",
    "# ----- Train model -----\n",
    "history = model.fit(train,\n",
    "\t\t\t\t\tepochs = 30,\n",
    "\t\t\t\t\tvalidation_data= val)\n",
    "\n",
    "# ----- Plot performance -----\n",
    "plot_hist(history)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of simple model\n",
    "\n",
    "The first results from the experiment with the simple model shows a promising accuracy of 83.xx%, which is significantly higher than the random classifier that has the expected prediction of 50/50. Futhermore, the plots of the accuracy over 30 epochs shows a rather fluctuating accuracy score, which could be an indication of a learning rate that is too high. Thus, for the next step in the procedure, we adjust the learning rate aswell as trying a setting with Stochastic Gradient Descent (SGD) as an alternative optimizer.\n",
    "\n",
    "According to Goodfellow et al. (2016) perhaps the most important hyperparameter is the learning rate, and if we only had time to tune a single parameter, it should be this one (p. 424). The learning rate controls the speed of the gradient descent process, i.e. how much to adjust the parameters in a single step (Chollet, 2021). If the learning rate is too small, results in too many iterations and the possibility of getting stuck at a local minimum. In contrary, too high of a learning rate could result in divergent behavior. Therefore, we try different values of the learning rate using the Adam optimizer. Due to time constraints of training with different optimizers and learning rates, we will only compare the Adam and (SGD) from Keras. This is reasonable because one... adaptive vs SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameters for tuning learning rate and optimizer\n",
    "\n",
    "learning_rates = [0.01, 0.001, 0.0001, 0.00001]\n",
    "momentum = [0.99, 0.9]\n",
    "nesterov = [True, False]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer: Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "82/82 [==============================] - 18s 212ms/step - loss: 1.1588 - accuracy: 0.4929 - val_loss: 0.6902 - val_accuracy: 0.5549\n",
      "Epoch 2/30\n",
      "82/82 [==============================] - 17s 210ms/step - loss: 0.6944 - accuracy: 0.4834 - val_loss: 0.6930 - val_accuracy: 0.5549\n",
      "Epoch 3/30\n",
      "82/82 [==============================] - 17s 209ms/step - loss: 0.6941 - accuracy: 0.4903 - val_loss: 0.6930 - val_accuracy: 0.5549\n",
      "Epoch 4/30\n",
      "82/82 [==============================] - 17s 211ms/step - loss: 0.6940 - accuracy: 0.4865 - val_loss: 0.6930 - val_accuracy: 0.5549\n",
      "Epoch 5/30\n",
      "82/82 [==============================] - 17s 211ms/step - loss: 0.6940 - accuracy: 0.4865 - val_loss: 0.6930 - val_accuracy: 0.5549\n",
      "Epoch 6/30\n",
      "82/82 [==============================] - 17s 209ms/step - loss: 0.6940 - accuracy: 0.4865 - val_loss: 0.6930 - val_accuracy: 0.5549\n",
      "Epoch 7/30\n",
      "82/82 [==============================] - 17s 209ms/step - loss: 0.6940 - accuracy: 0.4865 - val_loss: 0.6930 - val_accuracy: 0.5549\n",
      "Epoch 8/30\n",
      "82/82 [==============================] - 17s 212ms/step - loss: 0.6940 - accuracy: 0.4865 - val_loss: 0.6930 - val_accuracy: 0.5549\n",
      "Epoch 9/30\n",
      "82/82 [==============================] - 16s 200ms/step - loss: 0.6940 - accuracy: 0.4865 - val_loss: 0.6931 - val_accuracy: 0.5549\n",
      "Epoch 10/30\n",
      "82/82 [==============================] - 17s 203ms/step - loss: 0.6940 - accuracy: 0.4865 - val_loss: 0.6931 - val_accuracy: 0.5549\n",
      "Epoch 11/30\n",
      "82/82 [==============================] - 16s 199ms/step - loss: 0.6940 - accuracy: 0.4884 - val_loss: 0.6931 - val_accuracy: 0.5549\n",
      "Epoch 12/30\n",
      "82/82 [==============================] - 16s 200ms/step - loss: 0.6939 - accuracy: 0.4884 - val_loss: 0.6931 - val_accuracy: 0.5549\n",
      "Epoch 13/30\n",
      "82/82 [==============================] - 16s 199ms/step - loss: 0.6939 - accuracy: 0.4884 - val_loss: 0.6931 - val_accuracy: 0.5549\n",
      "Epoch 14/30\n",
      "82/82 [==============================] - 16s 199ms/step - loss: 0.6939 - accuracy: 0.4853 - val_loss: 0.6931 - val_accuracy: 0.5549\n",
      "Epoch 15/30\n",
      "82/82 [==============================] - 17s 211ms/step - loss: 0.6939 - accuracy: 0.4853 - val_loss: 0.6931 - val_accuracy: 0.5549\n",
      "Epoch 16/30\n",
      "82/82 [==============================] - 17s 204ms/step - loss: 0.6939 - accuracy: 0.4853 - val_loss: 0.6931 - val_accuracy: 0.5549\n",
      "Epoch 17/30\n",
      "82/82 [==============================] - 17s 206ms/step - loss: 0.6939 - accuracy: 0.4853 - val_loss: 0.6932 - val_accuracy: 0.4451\n",
      "Epoch 18/30\n",
      "82/82 [==============================] - 18s 215ms/step - loss: 0.6939 - accuracy: 0.4853 - val_loss: 0.6932 - val_accuracy: 0.4451\n",
      "Epoch 19/30\n",
      "82/82 [==============================] - 18s 216ms/step - loss: 0.6939 - accuracy: 0.4853 - val_loss: 0.6932 - val_accuracy: 0.4451\n",
      "Epoch 20/30\n",
      "82/82 [==============================] - 17s 209ms/step - loss: 0.6938 - accuracy: 0.4853 - val_loss: 0.6932 - val_accuracy: 0.4451\n",
      "Epoch 21/30\n",
      "82/82 [==============================] - 17s 211ms/step - loss: 0.6938 - accuracy: 0.4853 - val_loss: 0.6932 - val_accuracy: 0.4451\n",
      "Epoch 22/30\n",
      "82/82 [==============================] - 17s 210ms/step - loss: 0.6938 - accuracy: 0.4853 - val_loss: 0.6932 - val_accuracy: 0.4451\n",
      "Epoch 23/30\n",
      "82/82 [==============================] - 17s 207ms/step - loss: 0.6938 - accuracy: 0.4853 - val_loss: 0.6932 - val_accuracy: 0.4451\n",
      "Epoch 24/30\n",
      "82/82 [==============================] - 17s 202ms/step - loss: 0.6938 - accuracy: 0.4853 - val_loss: 0.6932 - val_accuracy: 0.4451\n",
      "Epoch 25/30\n",
      "82/82 [==============================] - 16s 199ms/step - loss: 0.6938 - accuracy: 0.4853 - val_loss: 0.6932 - val_accuracy: 0.4451\n",
      "Epoch 26/30\n",
      "82/82 [==============================] - 16s 199ms/step - loss: 0.6938 - accuracy: 0.4853 - val_loss: 0.6932 - val_accuracy: 0.4451\n",
      "Epoch 27/30\n",
      "82/82 [==============================] - 17s 205ms/step - loss: 0.6938 - accuracy: 0.4853 - val_loss: 0.6932 - val_accuracy: 0.4451\n",
      "Epoch 28/30\n",
      "82/82 [==============================] - 17s 203ms/step - loss: 0.6938 - accuracy: 0.4853 - val_loss: 0.6932 - val_accuracy: 0.4451\n",
      "Epoch 29/30\n",
      "82/82 [==============================] - 17s 205ms/step - loss: 0.6938 - accuracy: 0.4853 - val_loss: 0.6932 - val_accuracy: 0.4451\n",
      "Epoch 30/30\n",
      "82/82 [==============================] - 17s 204ms/step - loss: 0.6938 - accuracy: 0.4853 - val_loss: 0.6932 - val_accuracy: 0.4451\n",
      "Epoch 1/30\n",
      "82/82 [==============================] - 18s 212ms/step - loss: 0.6841 - accuracy: 0.5311 - val_loss: 0.6905 - val_accuracy: 0.4604\n",
      "Epoch 2/30\n",
      "82/82 [==============================] - 17s 211ms/step - loss: 0.5909 - accuracy: 0.6932 - val_loss: 0.5279 - val_accuracy: 0.7287\n",
      "Epoch 3/30\n",
      "82/82 [==============================] - 18s 215ms/step - loss: 0.5416 - accuracy: 0.7394 - val_loss: 0.4830 - val_accuracy: 0.7652\n",
      "Epoch 4/30\n",
      "82/82 [==============================] - 17s 208ms/step - loss: 0.5287 - accuracy: 0.7486 - val_loss: 0.4283 - val_accuracy: 0.8049\n",
      "Epoch 5/30\n",
      "82/82 [==============================] - 17s 212ms/step - loss: 0.5146 - accuracy: 0.7585 - val_loss: 0.4340 - val_accuracy: 0.7927\n",
      "Epoch 6/30\n",
      "82/82 [==============================] - 18s 217ms/step - loss: 0.5032 - accuracy: 0.7661 - val_loss: 0.4428 - val_accuracy: 0.7805\n",
      "Epoch 7/30\n",
      "82/82 [==============================] - 18s 221ms/step - loss: 0.4967 - accuracy: 0.7715 - val_loss: 0.4760 - val_accuracy: 0.7622\n",
      "Epoch 8/30\n",
      "82/82 [==============================] - 17s 212ms/step - loss: 0.4937 - accuracy: 0.7684 - val_loss: 0.4888 - val_accuracy: 0.7500\n",
      "Epoch 9/30\n",
      "82/82 [==============================] - 18s 215ms/step - loss: 0.4933 - accuracy: 0.7764 - val_loss: 0.5214 - val_accuracy: 0.7470\n",
      "Epoch 10/30\n",
      "82/82 [==============================] - 18s 220ms/step - loss: 0.4774 - accuracy: 0.7787 - val_loss: 0.5007 - val_accuracy: 0.7500\n",
      "Epoch 11/30\n",
      "82/82 [==============================] - 18s 225ms/step - loss: 0.4596 - accuracy: 0.7863 - val_loss: 0.5446 - val_accuracy: 0.7165\n",
      "Epoch 12/30\n",
      "82/82 [==============================] - 17s 205ms/step - loss: 0.4081 - accuracy: 0.8222 - val_loss: 0.5075 - val_accuracy: 0.7835\n",
      "Epoch 13/30\n",
      "82/82 [==============================] - 17s 212ms/step - loss: 0.3454 - accuracy: 0.8623 - val_loss: 0.5856 - val_accuracy: 0.7470\n",
      "Epoch 14/30\n",
      "82/82 [==============================] - 18s 217ms/step - loss: 0.3123 - accuracy: 0.8672 - val_loss: 0.7183 - val_accuracy: 0.7043\n",
      "Epoch 15/30\n",
      "82/82 [==============================] - 17s 207ms/step - loss: 0.2812 - accuracy: 0.8806 - val_loss: 0.8493 - val_accuracy: 0.6799\n",
      "Epoch 16/30\n",
      "82/82 [==============================] - 17s 208ms/step - loss: 0.3007 - accuracy: 0.8714 - val_loss: 0.6949 - val_accuracy: 0.7591\n",
      "Epoch 17/30\n",
      "82/82 [==============================] - 17s 205ms/step - loss: 0.2228 - accuracy: 0.9096 - val_loss: 0.6332 - val_accuracy: 0.7652\n",
      "Epoch 18/30\n",
      "82/82 [==============================] - 17s 204ms/step - loss: 0.1797 - accuracy: 0.9309 - val_loss: 0.7682 - val_accuracy: 0.7591\n",
      "Epoch 19/30\n",
      "82/82 [==============================] - 17s 204ms/step - loss: 0.1551 - accuracy: 0.9428 - val_loss: 1.2529 - val_accuracy: 0.7043\n",
      "Epoch 20/30\n",
      "82/82 [==============================] - 17s 204ms/step - loss: 0.1161 - accuracy: 0.9592 - val_loss: 1.1948 - val_accuracy: 0.7409\n",
      "Epoch 21/30\n",
      "82/82 [==============================] - 17s 206ms/step - loss: 0.0854 - accuracy: 0.9683 - val_loss: 1.5194 - val_accuracy: 0.7226\n",
      "Epoch 22/30\n",
      "82/82 [==============================] - 17s 207ms/step - loss: 0.0884 - accuracy: 0.9702 - val_loss: 1.3965 - val_accuracy: 0.7409\n",
      "Epoch 23/30\n",
      "82/82 [==============================] - 17s 206ms/step - loss: 0.0697 - accuracy: 0.9760 - val_loss: 1.5506 - val_accuracy: 0.7165\n",
      "Epoch 24/30\n",
      "82/82 [==============================] - 17s 203ms/step - loss: 0.0693 - accuracy: 0.9737 - val_loss: 1.4469 - val_accuracy: 0.7226\n",
      "Epoch 25/30\n",
      "82/82 [==============================] - 17s 205ms/step - loss: 0.0624 - accuracy: 0.9802 - val_loss: 1.4892 - val_accuracy: 0.7561\n",
      "Epoch 26/30\n",
      "82/82 [==============================] - 17s 206ms/step - loss: 0.0366 - accuracy: 0.9886 - val_loss: 1.8112 - val_accuracy: 0.7409\n",
      "Epoch 27/30\n",
      "82/82 [==============================] - 17s 206ms/step - loss: 0.0327 - accuracy: 0.9893 - val_loss: 1.8594 - val_accuracy: 0.7561\n",
      "Epoch 28/30\n",
      "82/82 [==============================] - 17s 208ms/step - loss: 0.0492 - accuracy: 0.9828 - val_loss: 1.7077 - val_accuracy: 0.7713\n",
      "Epoch 29/30\n",
      "82/82 [==============================] - 17s 210ms/step - loss: 0.0419 - accuracy: 0.9878 - val_loss: 2.0677 - val_accuracy: 0.7287\n",
      "Epoch 30/30\n",
      "82/82 [==============================] - 17s 207ms/step - loss: 0.0334 - accuracy: 0.9886 - val_loss: 2.0472 - val_accuracy: 0.7713\n",
      "Epoch 1/30\n",
      "82/82 [==============================] - 19s 224ms/step - loss: 0.6566 - accuracy: 0.6284 - val_loss: 0.4840 - val_accuracy: 0.8262\n",
      "Epoch 2/30\n",
      "82/82 [==============================] - 19s 226ms/step - loss: 0.5426 - accuracy: 0.7303 - val_loss: 0.4262 - val_accuracy: 0.8110\n",
      "Epoch 3/30\n",
      "82/82 [==============================] - 18s 225ms/step - loss: 0.5230 - accuracy: 0.7470 - val_loss: 0.4264 - val_accuracy: 0.8049\n",
      "Epoch 4/30\n",
      "82/82 [==============================] - 19s 226ms/step - loss: 0.5074 - accuracy: 0.7577 - val_loss: 0.4256 - val_accuracy: 0.8049\n",
      "Epoch 5/30\n",
      "82/82 [==============================] - 18s 222ms/step - loss: 0.5007 - accuracy: 0.7573 - val_loss: 0.4215 - val_accuracy: 0.8140\n",
      "Epoch 6/30\n",
      "82/82 [==============================] - 18s 222ms/step - loss: 0.4958 - accuracy: 0.7619 - val_loss: 0.4201 - val_accuracy: 0.8201\n",
      "Epoch 7/30\n",
      "82/82 [==============================] - 18s 222ms/step - loss: 0.4910 - accuracy: 0.7642 - val_loss: 0.4177 - val_accuracy: 0.8232\n",
      "Epoch 8/30\n",
      "82/82 [==============================] - 18s 225ms/step - loss: 0.4856 - accuracy: 0.7673 - val_loss: 0.4140 - val_accuracy: 0.8232\n",
      "Epoch 9/30\n",
      "82/82 [==============================] - 18s 223ms/step - loss: 0.4800 - accuracy: 0.7692 - val_loss: 0.4132 - val_accuracy: 0.8262\n",
      "Epoch 10/30\n",
      "82/82 [==============================] - 19s 226ms/step - loss: 0.4733 - accuracy: 0.7734 - val_loss: 0.4104 - val_accuracy: 0.8171\n",
      "Epoch 11/30\n",
      "82/82 [==============================] - 18s 225ms/step - loss: 0.4651 - accuracy: 0.7783 - val_loss: 0.4024 - val_accuracy: 0.8140\n",
      "Epoch 12/30\n",
      "82/82 [==============================] - 18s 222ms/step - loss: 0.4558 - accuracy: 0.7825 - val_loss: 0.3958 - val_accuracy: 0.8171\n",
      "Epoch 13/30\n",
      "82/82 [==============================] - 18s 223ms/step - loss: 0.4450 - accuracy: 0.7902 - val_loss: 0.3925 - val_accuracy: 0.8293\n",
      "Epoch 14/30\n",
      "82/82 [==============================] - 18s 222ms/step - loss: 0.4318 - accuracy: 0.7970 - val_loss: 0.3924 - val_accuracy: 0.8262\n",
      "Epoch 15/30\n",
      "82/82 [==============================] - 18s 224ms/step - loss: 0.4166 - accuracy: 0.8089 - val_loss: 0.3934 - val_accuracy: 0.8171\n",
      "Epoch 16/30\n",
      "82/82 [==============================] - 18s 222ms/step - loss: 0.3992 - accuracy: 0.8214 - val_loss: 0.3976 - val_accuracy: 0.8140\n",
      "Epoch 17/30\n",
      "82/82 [==============================] - 18s 223ms/step - loss: 0.3781 - accuracy: 0.8340 - val_loss: 0.4048 - val_accuracy: 0.8079\n",
      "Epoch 18/30\n",
      "82/82 [==============================] - 18s 222ms/step - loss: 0.3525 - accuracy: 0.8535 - val_loss: 0.4114 - val_accuracy: 0.8049\n",
      "Epoch 19/30\n",
      "82/82 [==============================] - 18s 222ms/step - loss: 0.3238 - accuracy: 0.8707 - val_loss: 0.4208 - val_accuracy: 0.7957\n",
      "Epoch 20/30\n",
      "82/82 [==============================] - 18s 223ms/step - loss: 0.2900 - accuracy: 0.8878 - val_loss: 0.4308 - val_accuracy: 0.7988\n",
      "Epoch 21/30\n",
      "82/82 [==============================] - 18s 222ms/step - loss: 0.2549 - accuracy: 0.9145 - val_loss: 0.4438 - val_accuracy: 0.7957\n",
      "Epoch 22/30\n",
      "82/82 [==============================] - 18s 222ms/step - loss: 0.2198 - accuracy: 0.9321 - val_loss: 0.4591 - val_accuracy: 0.8018\n",
      "Epoch 23/30\n",
      "82/82 [==============================] - 18s 223ms/step - loss: 0.1958 - accuracy: 0.9451 - val_loss: 0.4869 - val_accuracy: 0.7805\n",
      "Epoch 24/30\n",
      "82/82 [==============================] - 18s 223ms/step - loss: 0.1870 - accuracy: 0.9458 - val_loss: 0.4732 - val_accuracy: 0.7927\n",
      "Epoch 25/30\n",
      "82/82 [==============================] - 19s 231ms/step - loss: 0.1533 - accuracy: 0.9580 - val_loss: 0.5600 - val_accuracy: 0.7622\n",
      "Epoch 26/30\n",
      "82/82 [==============================] - 19s 237ms/step - loss: 0.1261 - accuracy: 0.9691 - val_loss: 0.7430 - val_accuracy: 0.7439\n",
      "Epoch 27/30\n",
      "82/82 [==============================] - 21s 253ms/step - loss: 0.1291 - accuracy: 0.9649 - val_loss: 0.6342 - val_accuracy: 0.7622\n",
      "Epoch 28/30\n",
      "82/82 [==============================] - 19s 230ms/step - loss: 0.1193 - accuracy: 0.9695 - val_loss: 0.6152 - val_accuracy: 0.7622\n",
      "Epoch 29/30\n",
      "82/82 [==============================] - 18s 225ms/step - loss: 0.1308 - accuracy: 0.9645 - val_loss: 0.5534 - val_accuracy: 0.7774\n",
      "Epoch 30/30\n",
      "82/82 [==============================] - 19s 229ms/step - loss: 0.0979 - accuracy: 0.9775 - val_loss: 0.5476 - val_accuracy: 0.7896\n",
      "Epoch 1/30\n",
      "82/82 [==============================] - 19s 223ms/step - loss: 0.6926 - accuracy: 0.4956 - val_loss: 0.6866 - val_accuracy: 0.5579\n",
      "Epoch 2/30\n",
      "82/82 [==============================] - 19s 230ms/step - loss: 0.6889 - accuracy: 0.5399 - val_loss: 0.6801 - val_accuracy: 0.6341\n",
      "Epoch 3/30\n",
      "82/82 [==============================] - 18s 224ms/step - loss: 0.6829 - accuracy: 0.6002 - val_loss: 0.6688 - val_accuracy: 0.7012\n",
      "Epoch 4/30\n",
      "82/82 [==============================] - 19s 235ms/step - loss: 0.6729 - accuracy: 0.6356 - val_loss: 0.6511 - val_accuracy: 0.7317\n",
      "Epoch 5/30\n",
      "82/82 [==============================] - 19s 232ms/step - loss: 0.6566 - accuracy: 0.6627 - val_loss: 0.6251 - val_accuracy: 0.7988\n",
      "Epoch 6/30\n",
      "82/82 [==============================] - 18s 224ms/step - loss: 0.6321 - accuracy: 0.6940 - val_loss: 0.5916 - val_accuracy: 0.7957\n",
      "Epoch 7/30\n",
      "82/82 [==============================] - 18s 224ms/step - loss: 0.6039 - accuracy: 0.7173 - val_loss: 0.5557 - val_accuracy: 0.7957\n",
      "Epoch 8/30\n",
      "82/82 [==============================] - 18s 223ms/step - loss: 0.5784 - accuracy: 0.7348 - val_loss: 0.5264 - val_accuracy: 0.7835\n",
      "Epoch 9/30\n",
      "82/82 [==============================] - 18s 225ms/step - loss: 0.5586 - accuracy: 0.7337 - val_loss: 0.5047 - val_accuracy: 0.7927\n",
      "Epoch 10/30\n",
      "82/82 [==============================] - 18s 223ms/step - loss: 0.5446 - accuracy: 0.7383 - val_loss: 0.4891 - val_accuracy: 0.7805\n",
      "Epoch 11/30\n",
      "82/82 [==============================] - 18s 223ms/step - loss: 0.5345 - accuracy: 0.7413 - val_loss: 0.4769 - val_accuracy: 0.7835\n",
      "Epoch 12/30\n",
      "82/82 [==============================] - 19s 232ms/step - loss: 0.5271 - accuracy: 0.7451 - val_loss: 0.4681 - val_accuracy: 0.7927\n",
      "Epoch 13/30\n",
      "82/82 [==============================] - 19s 236ms/step - loss: 0.5216 - accuracy: 0.7505 - val_loss: 0.4610 - val_accuracy: 0.7927\n",
      "Epoch 14/30\n",
      "82/82 [==============================] - 19s 235ms/step - loss: 0.5173 - accuracy: 0.7551 - val_loss: 0.4558 - val_accuracy: 0.7957\n",
      "Epoch 15/30\n",
      "82/82 [==============================] - 19s 230ms/step - loss: 0.5140 - accuracy: 0.7570 - val_loss: 0.4516 - val_accuracy: 0.8018\n",
      "Epoch 16/30\n",
      "82/82 [==============================] - 19s 237ms/step - loss: 0.5111 - accuracy: 0.7573 - val_loss: 0.4481 - val_accuracy: 0.7988\n",
      "Epoch 17/30\n",
      "82/82 [==============================] - 19s 236ms/step - loss: 0.5087 - accuracy: 0.7589 - val_loss: 0.4452 - val_accuracy: 0.8049\n",
      "Epoch 18/30\n",
      "82/82 [==============================] - 19s 227ms/step - loss: 0.5066 - accuracy: 0.7577 - val_loss: 0.4429 - val_accuracy: 0.8018\n",
      "Epoch 19/30\n",
      "82/82 [==============================] - 19s 226ms/step - loss: 0.5048 - accuracy: 0.7593 - val_loss: 0.4409 - val_accuracy: 0.7957\n",
      "Epoch 20/30\n",
      "82/82 [==============================] - 19s 227ms/step - loss: 0.5032 - accuracy: 0.7600 - val_loss: 0.4391 - val_accuracy: 0.7957\n",
      "Epoch 21/30\n",
      "82/82 [==============================] - 19s 227ms/step - loss: 0.5017 - accuracy: 0.7600 - val_loss: 0.4376 - val_accuracy: 0.7988\n",
      "Epoch 22/30\n",
      "82/82 [==============================] - 19s 234ms/step - loss: 0.5005 - accuracy: 0.7608 - val_loss: 0.4362 - val_accuracy: 0.8049\n",
      "Epoch 23/30\n",
      "82/82 [==============================] - 19s 235ms/step - loss: 0.4993 - accuracy: 0.7600 - val_loss: 0.4350 - val_accuracy: 0.8018\n",
      "Epoch 24/30\n",
      "82/82 [==============================] - 19s 232ms/step - loss: 0.4981 - accuracy: 0.7608 - val_loss: 0.4338 - val_accuracy: 0.8018\n",
      "Epoch 25/30\n",
      "82/82 [==============================] - 19s 233ms/step - loss: 0.4971 - accuracy: 0.7604 - val_loss: 0.4329 - val_accuracy: 0.8018\n",
      "Epoch 26/30\n",
      "82/82 [==============================] - 19s 232ms/step - loss: 0.4961 - accuracy: 0.7604 - val_loss: 0.4320 - val_accuracy: 0.8018\n",
      "Epoch 27/30\n",
      "82/82 [==============================] - 20s 241ms/step - loss: 0.4952 - accuracy: 0.7615 - val_loss: 0.4310 - val_accuracy: 0.7988\n",
      "Epoch 28/30\n",
      "82/82 [==============================] - 20s 240ms/step - loss: 0.4942 - accuracy: 0.7612 - val_loss: 0.4302 - val_accuracy: 0.7957\n",
      "Epoch 29/30\n",
      "42/82 [==============>...............] - ETA: 9s - loss: 0.5120 - accuracy: 0.7440"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\chrse\\Desktop\\applied_ML_faelles\\exam\\question_2\\faelles.ipynb Cell 10\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/faelles.ipynb#X14sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m current_model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mopt,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/faelles.ipynb#X14sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \t\t  \tloss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/faelles.ipynb#X14sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \t\t  metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/faelles.ipynb#X14sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m# ----- Train model -----\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/faelles.ipynb#X14sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m history \u001b[39m=\u001b[39m current_model\u001b[39m.\u001b[39;49mfit(train,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/faelles.ipynb#X14sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \t\t\t\t\tepochs\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/faelles.ipynb#X14sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \t\t\t\t\tvalidation_data\u001b[39m=\u001b[39;49mval)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/faelles.ipynb#X14sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m# ----- Plot performance -----\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/faelles.ipynb#X14sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m acc \u001b[39m=\u001b[39m history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def simple_model():\n",
    "\tinputs = Input(shape=(96, 96, 3))\n",
    "\tx = Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
    "\tx = MaxPooling2D(pool_size=2)(x)\n",
    "\tx = Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "\tx = MaxPooling2D(pool_size=2)(x)\n",
    "\tx = Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "\tx = MaxPooling2D(pool_size=2)(x)\n",
    "\tx = Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "\tx = MaxPooling2D(pool_size=2)(x)\n",
    "\tx = Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "\tx = Flatten()(x)\n",
    "\toutputs = Dense(2, activation=\"softmax\")(x)\n",
    "\tmodel = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "\treturn model\n",
    "\n",
    "# ----- Define subplot grid -----\n",
    "fig, axis = plt.subplots(nrows=1, ncols=4, figsize=(10, 4))\n",
    "plt.subplots_adjust(hspace=0.8)\n",
    "fig.suptitle(\"Model accuracy for different learning rates with Adam\", fontsize=12, y=1)\n",
    "\n",
    "# Try different learning rates for Adam optimizer\n",
    "for i in range(len(learning_rates)):\n",
    "\topt = tf.keras.optimizers.Adam(learning_rate=learning_rates[i])\n",
    "\n",
    "\tcurrent_model = simple_model()\n",
    "\n",
    "\t# ----- Configure model -----\n",
    "\tcurrent_model.compile(optimizer=opt,\n",
    "\t\t\t  \tloss='categorical_crossentropy',\n",
    "\t\t\t  metrics=['accuracy'])\n",
    "\n",
    "\t# ----- Train model -----\n",
    "\thistory = current_model.fit(train,\n",
    "\t\t\t\t\t\tepochs=30,\n",
    "\t\t\t\t\t\tvalidation_data=val)\n",
    "\n",
    "\t# ----- Plot performance -----\n",
    "\tacc = history.history['accuracy']\n",
    "\tval_acc = history.history['val_accuracy']\n",
    "\tepochs = range(1, len(acc) + 1)\n",
    "\n",
    "\taxis[i].plot(epochs, acc, 'r--', label='Training accuracy')\n",
    "\taxis[i].plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
    "\taxis[i].set_title('lr='+str(learning_rates[i]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Define subplot grid -----\n",
    "fig, axis = plt.subplots(nrows=4, ncols=4, figsize=(12, 12))\n",
    "plt.subplots_adjust(hspace=0.8)\n",
    "fig.suptitle(\"Model accuracy for different learning- and momentum rates for SGD\", fontsize=12, y=1)\n",
    "\n",
    "t=1\n",
    "# Try different learning rates, momentum, and nesterov for SGD optimizer\n",
    "for i in range(len(learning_rates)):\n",
    "\tfor m in range(len(momentum)):\n",
    "\t\tfor n in range(len(nesterov)):\n",
    "\n",
    "\t\t\tcurrent_model = simple_model()\n",
    "\n",
    "\t\t\topt = tf.keras.optimizers.SGD(learning_rate=learning_rates[i],\n",
    "\t\t\t\t\t\t\t\t\t\t  momentum=momentum[m],\n",
    "\t\t\t\t\t\t\t\t\t\t  nesterov=nesterov[n])\n",
    "\n",
    "\t\t\t# ----- Configure model -----\n",
    "\t\t\tcurrent_model.compile(optimizer=opt,\n",
    "\t\t\t\t\t\tloss='categorical_crossentropy',\n",
    "\t\t\t\t\tmetrics=['accuracy'])\n",
    "\n",
    "\t\t\t# ----- Train model -----\n",
    "\t\t\thistory = current_model.fit(train,\n",
    "\t\t\t\t\t\t\t\tepochs=30,\n",
    "\t\t\t\t\t\t\t\tvalidation_data=val)\n",
    "\n",
    "\t\t\t# ----- Plot performance -----\n",
    "\t\t\tacc = history.history['accuracy']\n",
    "\t\t\tval_acc = history.history['val_accuracy']\n",
    "\t\t\tepochs = range(1, len(acc) + 1)\n",
    "\n",
    "\t\t\taxis = plt.subplot(4, 4, t)\n",
    "\t\t\taxis.plot(epochs, acc, label='Training accuracy')\n",
    "\t\t\taxis.plot(epochs, val_acc, label='Validation accuracy')\n",
    "\t\t\taxis.set_title('lr=' + str(learning_rates[i]) + ', momen=' + str(momentum[m]) + ', nest=' + str(nesterov[n]))\n",
    "\t\t\tt=t+1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of learning rates and momentum for Adam and SGD\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization 1: Adjustments to the architecture\n",
    "\n",
    "- Add/remove layers\n",
    "- Adjust number of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_62 (InputLayer)       [(None, 96, 96, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_335 (Conv2D)         (None, 94, 94, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_266 (MaxPooli  (None, 47, 47, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_336 (Conv2D)         (None, 45, 45, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_267 (MaxPooli  (None, 22, 22, 64)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_337 (Conv2D)         (None, 20, 20, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_268 (MaxPooli  (None, 10, 10, 128)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_338 (Conv2D)         (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " max_pooling2d_269 (MaxPooli  (None, 4, 4, 256)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_339 (Conv2D)         (None, 2, 2, 256)         590080    \n",
      "                                                                 \n",
      " flatten_37 (Flatten)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 2)                 2050      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 980,546\n",
      "Trainable params: 980,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_36\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_62 (InputLayer)       [(None, 96, 96, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_335 (Conv2D)         (None, 94, 94, 32)        896       \n",
      "                                                                 \n",
      " max_pooling2d_266 (MaxPooli  (None, 47, 47, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_336 (Conv2D)         (None, 45, 45, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_267 (MaxPooli  (None, 22, 22, 64)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_337 (Conv2D)         (None, 20, 20, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_268 (MaxPooli  (None, 10, 10, 128)      0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_338 (Conv2D)         (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " max_pooling2d_269 (MaxPooli  (None, 4, 4, 256)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_339 (Conv2D)         (None, 2, 2, 256)         590080    \n",
      "                                                                 \n",
      " flatten_37 (Flatten)        (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 2)                 2050      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 980,546\n",
      "Trainable params: 980,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "82/82 [==============================] - 19s 227ms/step - loss: 0.6632 - accuracy: 0.6253 - val_loss: 0.5110 - val_accuracy: 0.8201\n",
      "Epoch 2/30\n",
      "82/82 [==============================] - 18s 223ms/step - loss: 0.5426 - accuracy: 0.7333 - val_loss: 0.4268 - val_accuracy: 0.8171\n",
      "Epoch 3/30\n",
      "82/82 [==============================] - 18s 222ms/step - loss: 0.5312 - accuracy: 0.7398 - val_loss: 0.4386 - val_accuracy: 0.8018\n",
      "Epoch 4/30\n",
      "82/82 [==============================] - 18s 222ms/step - loss: 0.5139 - accuracy: 0.7531 - val_loss: 0.4356 - val_accuracy: 0.8079\n",
      "Epoch 5/30\n",
      "82/82 [==============================] - 18s 221ms/step - loss: 0.5066 - accuracy: 0.7562 - val_loss: 0.4320 - val_accuracy: 0.8049\n",
      "Epoch 6/30\n",
      "82/82 [==============================] - 19s 226ms/step - loss: 0.5009 - accuracy: 0.7608 - val_loss: 0.4281 - val_accuracy: 0.8110\n",
      "Epoch 7/30\n",
      "82/82 [==============================] - 18s 224ms/step - loss: 0.4957 - accuracy: 0.7589 - val_loss: 0.4270 - val_accuracy: 0.8049\n",
      "Epoch 8/30\n",
      "82/82 [==============================] - 18s 223ms/step - loss: 0.4904 - accuracy: 0.7650 - val_loss: 0.4241 - val_accuracy: 0.8171\n",
      "Epoch 9/30\n",
      "82/82 [==============================] - 19s 228ms/step - loss: 0.4844 - accuracy: 0.7669 - val_loss: 0.4215 - val_accuracy: 0.8201\n",
      "Epoch 10/30\n",
      "82/82 [==============================] - 19s 232ms/step - loss: 0.4782 - accuracy: 0.7722 - val_loss: 0.4209 - val_accuracy: 0.8140\n",
      "Epoch 11/30\n",
      "82/82 [==============================] - 19s 229ms/step - loss: 0.4703 - accuracy: 0.7772 - val_loss: 0.4203 - val_accuracy: 0.8171\n",
      "Epoch 12/30\n",
      "82/82 [==============================] - 19s 237ms/step - loss: 0.4611 - accuracy: 0.7837 - val_loss: 0.4199 - val_accuracy: 0.8018\n",
      "Epoch 13/30\n",
      "82/82 [==============================] - 19s 228ms/step - loss: 0.4491 - accuracy: 0.7905 - val_loss: 0.4175 - val_accuracy: 0.8018\n",
      "Epoch 14/30\n",
      "82/82 [==============================] - 18s 225ms/step - loss: 0.4363 - accuracy: 0.7955 - val_loss: 0.4154 - val_accuracy: 0.8049\n",
      "Epoch 15/30\n",
      "40/82 [=============>................] - ETA: 9s - loss: 0.4450 - accuracy: 0.7937"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\chrse\\Desktop\\applied_ML_faelles\\exam\\question_2\\faelles.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/faelles.ipynb#X32sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mopt,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/faelles.ipynb#X32sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \t\t\t  loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/faelles.ipynb#X32sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \t\t\t  metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/faelles.ipynb#X32sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# ----- Train model -----\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/faelles.ipynb#X32sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/faelles.ipynb#X32sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \t\t\t\t\tepochs \u001b[39m=\u001b[39;49m \u001b[39m30\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/faelles.ipynb#X32sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \t\t\t\t\tvalidation_data\u001b[39m=\u001b[39;49m val)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/faelles.ipynb#X32sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# ----- Plot performance -----\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/chrse/Desktop/applied_ML_faelles/exam/question_2/faelles.ipynb#X32sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m plot_hist(history)\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\chrse\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(96, 96, 3))\n",
    "x = Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "x = Flatten()(x)\n",
    "outputs = Dense(2, activation=\"softmax\")(x)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()\n",
    "\n",
    "# ----- Model summary -----\n",
    "model.summary()\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "# ----- Configure model -----\n",
    "model.compile(optimizer=opt,\n",
    "\t\t\t  loss='categorical_crossentropy',\n",
    "\t\t\t  metrics=['accuracy'])\n",
    "\n",
    "# ----- Train model -----\n",
    "history = model.fit(train,\n",
    "\t\t\t\t\tepochs = 30,\n",
    "\t\t\t\t\tvalidation_data= val)\n",
    "\n",
    "# ----- Plot performance -----\n",
    "plot_hist(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_65 (InputLayer)       [(None, 96, 96, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_354 (Conv2D)         (None, 96, 96, 16)        448       \n",
      "                                                                 \n",
      " max_pooling2d_282 (MaxPooli  (None, 48, 48, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_355 (Conv2D)         (None, 48, 48, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_283 (MaxPooli  (None, 24, 24, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_356 (Conv2D)         (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_284 (MaxPooli  (None, 12, 12, 64)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_357 (Conv2D)         (None, 12, 12, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_285 (MaxPooli  (None, 6, 6, 64)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_358 (Conv2D)         (None, 6, 6, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_286 (MaxPooli  (None, 3, 3, 128)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_359 (Conv2D)         (None, 3, 3, 256)         295168    \n",
      "                                                                 \n",
      " max_pooling2d_287 (MaxPooli  (None, 1, 1, 256)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_360 (Conv2D)         (None, 1, 1, 512)         1180160   \n",
      "                                                                 \n",
      " flatten_40 (Flatten)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 128)               65664     \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,692,130\n",
      "Trainable params: 1,692,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_39\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_65 (InputLayer)       [(None, 96, 96, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_354 (Conv2D)         (None, 96, 96, 16)        448       \n",
      "                                                                 \n",
      " max_pooling2d_282 (MaxPooli  (None, 48, 48, 16)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_355 (Conv2D)         (None, 48, 48, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_283 (MaxPooli  (None, 24, 24, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_356 (Conv2D)         (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_284 (MaxPooli  (None, 12, 12, 64)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_357 (Conv2D)         (None, 12, 12, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_285 (MaxPooli  (None, 6, 6, 64)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_358 (Conv2D)         (None, 6, 6, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_286 (MaxPooli  (None, 3, 3, 128)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_359 (Conv2D)         (None, 3, 3, 256)         295168    \n",
      "                                                                 \n",
      " max_pooling2d_287 (MaxPooli  (None, 1, 1, 256)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_360 (Conv2D)         (None, 1, 1, 512)         1180160   \n",
      "                                                                 \n",
      " flatten_40 (Flatten)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 128)               65664     \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,692,130\n",
      "Trainable params: 1,692,130\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "82/82 [==============================] - 19s 220ms/step - loss: 0.6909 - accuracy: 0.4987 - val_loss: 0.6725 - val_accuracy: 0.8110\n",
      "Epoch 2/30\n",
      "82/82 [==============================] - 18s 216ms/step - loss: 0.6023 - accuracy: 0.6883 - val_loss: 0.4233 - val_accuracy: 0.7957\n",
      "Epoch 3/30\n",
      "82/82 [==============================] - 18s 217ms/step - loss: 0.5426 - accuracy: 0.7364 - val_loss: 0.4155 - val_accuracy: 0.8140\n",
      "Epoch 4/30\n",
      "82/82 [==============================] - 18s 215ms/step - loss: 0.5281 - accuracy: 0.7444 - val_loss: 0.4124 - val_accuracy: 0.8140\n",
      "Epoch 5/30\n",
      "82/82 [==============================] - 18s 216ms/step - loss: 0.5149 - accuracy: 0.7528 - val_loss: 0.4121 - val_accuracy: 0.8079\n",
      "Epoch 6/30\n",
      "82/82 [==============================] - 18s 216ms/step - loss: 0.5065 - accuracy: 0.7593 - val_loss: 0.4096 - val_accuracy: 0.8110\n",
      "Epoch 7/30\n",
      "82/82 [==============================] - 18s 217ms/step - loss: 0.5012 - accuracy: 0.7615 - val_loss: 0.4103 - val_accuracy: 0.8171\n",
      "Epoch 8/30\n",
      "82/82 [==============================] - 18s 215ms/step - loss: 0.4942 - accuracy: 0.7661 - val_loss: 0.4105 - val_accuracy: 0.8049\n",
      "Epoch 9/30\n",
      "82/82 [==============================] - 18s 216ms/step - loss: 0.4879 - accuracy: 0.7703 - val_loss: 0.4147 - val_accuracy: 0.8049\n",
      "Epoch 10/30\n",
      "82/82 [==============================] - 18s 216ms/step - loss: 0.4814 - accuracy: 0.7753 - val_loss: 0.4158 - val_accuracy: 0.8110\n",
      "Epoch 11/30\n",
      "82/82 [==============================] - 18s 223ms/step - loss: 0.4754 - accuracy: 0.7776 - val_loss: 0.4162 - val_accuracy: 0.8079\n",
      "Epoch 12/30\n",
      "82/82 [==============================] - 19s 229ms/step - loss: 0.4700 - accuracy: 0.7779 - val_loss: 0.4133 - val_accuracy: 0.8049\n",
      "Epoch 13/30\n",
      "82/82 [==============================] - 18s 223ms/step - loss: 0.4645 - accuracy: 0.7802 - val_loss: 0.4119 - val_accuracy: 0.8018\n",
      "Epoch 14/30\n",
      "82/82 [==============================] - 18s 219ms/step - loss: 0.4590 - accuracy: 0.7837 - val_loss: 0.4101 - val_accuracy: 0.8110\n",
      "Epoch 15/30\n",
      "82/82 [==============================] - 18s 218ms/step - loss: 0.4525 - accuracy: 0.7890 - val_loss: 0.4094 - val_accuracy: 0.8049\n",
      "Epoch 16/30\n",
      "82/82 [==============================] - 18s 218ms/step - loss: 0.4468 - accuracy: 0.7924 - val_loss: 0.4095 - val_accuracy: 0.8140\n",
      "Epoch 17/30\n",
      "82/82 [==============================] - 18s 219ms/step - loss: 0.4390 - accuracy: 0.7982 - val_loss: 0.4090 - val_accuracy: 0.8140\n",
      "Epoch 18/30\n",
      "82/82 [==============================] - 18s 218ms/step - loss: 0.4323 - accuracy: 0.8012 - val_loss: 0.4081 - val_accuracy: 0.8140\n",
      "Epoch 19/30\n",
      "82/82 [==============================] - 18s 218ms/step - loss: 0.4237 - accuracy: 0.8085 - val_loss: 0.4083 - val_accuracy: 0.8140\n",
      "Epoch 20/30\n",
      "82/82 [==============================] - 18s 218ms/step - loss: 0.4136 - accuracy: 0.8127 - val_loss: 0.4083 - val_accuracy: 0.8079\n",
      "Epoch 21/30\n",
      "82/82 [==============================] - 18s 218ms/step - loss: 0.4037 - accuracy: 0.8211 - val_loss: 0.4111 - val_accuracy: 0.7957\n",
      "Epoch 22/30\n",
      "82/82 [==============================] - 18s 219ms/step - loss: 0.3876 - accuracy: 0.8325 - val_loss: 0.4173 - val_accuracy: 0.8018\n",
      "Epoch 23/30\n",
      "82/82 [==============================] - 18s 218ms/step - loss: 0.3673 - accuracy: 0.8451 - val_loss: 0.4318 - val_accuracy: 0.7988\n",
      "Epoch 24/30\n",
      "82/82 [==============================] - 18s 218ms/step - loss: 0.3431 - accuracy: 0.8531 - val_loss: 0.4521 - val_accuracy: 0.8018\n",
      "Epoch 25/30\n",
      "82/82 [==============================] - 18s 218ms/step - loss: 0.3092 - accuracy: 0.8729 - val_loss: 0.5016 - val_accuracy: 0.7835\n",
      "Epoch 26/30\n",
      "82/82 [==============================] - 18s 219ms/step - loss: 0.2778 - accuracy: 0.8882 - val_loss: 0.5212 - val_accuracy: 0.7744\n",
      "Epoch 27/30\n",
      "82/82 [==============================] - 18s 225ms/step - loss: 0.2325 - accuracy: 0.9168 - val_loss: 0.5646 - val_accuracy: 0.7652\n",
      "Epoch 28/30\n",
      "82/82 [==============================] - 19s 236ms/step - loss: 0.1938 - accuracy: 0.9359 - val_loss: 0.6019 - val_accuracy: 0.7652\n",
      "Epoch 29/30\n",
      "82/82 [==============================] - 18s 224ms/step - loss: 0.1827 - accuracy: 0.9374 - val_loss: 0.6829 - val_accuracy: 0.7256\n",
      "Epoch 30/30\n",
      "82/82 [==============================] - 18s 217ms/step - loss: 0.1820 - accuracy: 0.9340 - val_loss: 0.9498 - val_accuracy: 0.6159\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "inputs = Input(shape=(96, 96, 3))\n",
    "x = Conv2D(filters=16, kernel_size=3, activation=\"relu\", padding='same')(inputs)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Conv2D(filters=32, kernel_size=3, activation=\"relu\", padding='same')(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Conv2D(filters=64, kernel_size=3, activation=\"relu\", padding='same')(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Conv2D(filters=64, kernel_size=3, activation=\"relu\", padding='same')(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Conv2D(filters=128, kernel_size=3, activation=\"relu\", padding='same')(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Conv2D(filters=256, kernel_size=3, activation=\"relu\", padding='same')(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Conv2D(filters=512, kernel_size=3, activation=\"relu\", padding='same')(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "outputs = Dense(2, activation=\"softmax\")(x)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()\n",
    "\n",
    "# ----- Model summary -----\n",
    "model.summary()\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "# ----- Configure model -----\n",
    "model.compile(optimizer=opt,\n",
    "\t\t\t  loss='categorical_crossentropy',\n",
    "\t\t\t  metrics=['accuracy'])\n",
    "\n",
    "# ----- Train model -----\n",
    "history = model.fit(train,\n",
    "\t\t\t\t\tepochs = 30,\n",
    "\t\t\t\t\tvalidation_data= val)\n",
    "\n",
    "# ----- Plot performance -----\n",
    "plot_hist(history)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization\n",
    "\n",
    "Regarding early stopping, we prefer to save the best model instead and let the model train for the chosen epochs.\n",
    "\n",
    "- L1/L2\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----- Relatively Simple Convnet from DLPR -----\n",
    "inputs = Input(shape=(96, 96, 3))\n",
    "x = Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "x = MaxPooling2D(pool_size=2)(x)\n",
    "x = Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n",
    "x = Flatten()(x)\n",
    "outputs = Dense(2, activation=\"softmax\")(x)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# ----- Model summary -----\n",
    "model.summary()\n",
    "\n",
    "# ----- Configure model -----\n",
    "model.compile(optimizer='adam',\n",
    "\t\t\t  loss='categorical_crossentropy',\n",
    "\t\t\t  metrics=['accuracy'])\n",
    "\n",
    "# ----- Train model -----\n",
    "history = model.fit(train,\n",
    "\t\t\t\t\tepochs = 2,\n",
    "\t\t\t\t\tvalidation_data= val)\n",
    "\n",
    "# ----- Plot performance -----\n",
    "plot_hist(history)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First model = Simple CNN from DLWP --> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9f103ef9cbf49316bd58993216c58d1294ab2db4d797a0ed3c394268b3d025fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
