{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jN7S7WVQZUZO"
      },
      "source": [
        "#### Loading and preparing the PCam data for training deep learning models using tensorflow dataset (tfds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SwYxBsjXZUZQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\andly\\.conda\\envs\\tf\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "#import os\n",
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"   # Delete if you have GPU's available\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, Flatten, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import os\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWJoR1_oZUZQ"
      },
      "source": [
        "Defining a function that splits images and labels and one-hot-encodes the labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yBKDXK9sZUZR"
      },
      "outputs": [],
      "source": [
        "def convert_sample(sample):\n",
        "    image, label = sample['image'], sample['label']  \n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    label = tf.one_hot(label, 2, dtype=tf.float32)\n",
        "    return image, label"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the code to change the data directory to your local folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GUSTAV\n",
        "data_dir = '/Users/gustavchristensen/Documents/SDU/MSc. Data Science/3. Semester - DT/Anvendt Maskinl√¶ring'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ANDREAS\n",
        "data_dir = r'C:\\Users\\andly\\OneDrive\\Dokumenter\\applied_ML_faelles'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DAVID\n",
        "data_dir ="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CHRISTOFFER K\n",
        "data_dir ="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CHRISTOFFER S\n",
        "data_dir ="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBn2P6Yo15tj"
      },
      "source": [
        "Next we use the tensorflow dataset API - tfds - to load data from your mounted google drive. Note this API requite that you should have copied the entire **patch_camelyon** folder from https://syddanskuni-my.sharepoint.com/:f:/g/personal/cmd_sam_sdu_dk/EiWD2LmuxCJBp-_tfGK7aL8Bair7l5z8FU5sp5pLjlhKwg?e=FLzWno to the /content/drive/MyDrive folder on your google drive:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "s87QMCspZUZR"
      },
      "outputs": [],
      "source": [
        "ds1,ds2,ds3 = tfds.load('patch_camelyon',split=['train[:10%]','test[:10%]','validation[:10%]'],\n",
        "                        data_dir = data_dir,\n",
        "                        download=False,\n",
        "                        shuffle_files=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dpsruvlZUZS"
      },
      "source": [
        "Next we simple transform the data (by the function convert sample described previously) and getting ready for training by splitting it into batches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TvFSb5XgZUZS"
      },
      "outputs": [],
      "source": [
        "train_dataset       = ds1.map(convert_sample).batch(32)\n",
        "validation_dataset  = ds3.map(convert_sample).batch(32)\n",
        "test_dataset        = ds2.map(convert_sample).batch(32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVOp8zd5ZUZS"
      },
      "source": [
        "The data is then ready to be applied for training, validation, testing etc...below just a very very simple illustration on how to construct and train a model based on the data we have prepared"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUTbw9rWZUZT",
        "outputId": "3ea3c82c-5c94-4352-f1d2-303c62db7be5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "820/820 [==============================] - 34s 32ms/step - loss: 0.6696 - accuracy: 0.5849 - val_loss: 0.6804 - val_accuracy: 0.5716\n",
            "Epoch 2/2\n",
            "820/820 [==============================] - 26s 31ms/step - loss: 0.5917 - accuracy: 0.6782 - val_loss: 0.5929 - val_accuracy: 0.7309\n"
          ]
        }
      ],
      "source": [
        "def first_ccn_model():\n",
        "    input_img = Input(shape=(96,96,3))\n",
        "    \n",
        "    x = Conv2D(16, (3, 3), padding='valid', activation='relu')(input_img)\n",
        "    x = Conv2D(32, (3, 3), padding='valid', activation='relu')(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(rate=0.2)(x)\n",
        "    y = Dense(2, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=input_img, outputs=y)\n",
        "    return model\n",
        "\n",
        "sgd_opt = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
        "\n",
        "model = first_ccn_model()\n",
        "\n",
        "model.compile(optimizer=sgd_opt,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "hist = model.fit(train_dataset,\n",
        "                 validation_data=validation_dataset,\n",
        "                 epochs=2)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tf",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "d58de3e4d66ce978d2428cdad84ecd7ffde961044bfc5196b31d780d235b4ff1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
