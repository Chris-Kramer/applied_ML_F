{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jN7S7WVQZUZO"
      },
      "source": [
        "#### Loading and preparing the PCam data for training deep learning models using tensorflow dataset (tfds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SwYxBsjXZUZQ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-01-24 20:34:51.507417: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/Users/gustavchristensen/Documents/SDU/MSc. Data Science/3. Semester - DT/Anvendt Maskinlæring/applied_ML_faelles/assignment_2/.venv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "#import os\n",
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"   # Delete if you have GPU's available\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, Flatten, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWJoR1_oZUZQ"
      },
      "source": [
        "Defining a function that splits images and labels and one-hot-encodes the labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yBKDXK9sZUZR"
      },
      "outputs": [],
      "source": [
        "def convert_sample(sample):\n",
        "    image, label = sample['image'], sample['label']  \n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    label = tf.one_hot(label, 2, dtype=tf.float32)\n",
        "    return image, label"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the code to change the data directory to your local folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GUSTAV\n",
        "data_dir = '/Users/gustavchristensen/Documents/SDU/MSc. Data Science/3. Semester - DT/Anvendt Maskinlæring'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ANDREAS\n",
        "data_dir ="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DAVID\n",
        "data_dir ="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CHRISTOFFER K\n",
        "data_dir ="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CHRISTOFFER S\n",
        "data_dir ="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBn2P6Yo15tj"
      },
      "source": [
        "Next we use the tensorflow dataset API - tfds - to load data from your mounted google drive. Note this API requite that you should have copied the entire **patch_camelyon** folder from https://syddanskuni-my.sharepoint.com/:f:/g/personal/cmd_sam_sdu_dk/EiWD2LmuxCJBp-_tfGK7aL8Bair7l5z8FU5sp5pLjlhKwg?e=FLzWno to the /content/drive/MyDrive folder on your google drive:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "s87QMCspZUZR"
      },
      "outputs": [],
      "source": [
        "ds1,ds2,ds3 = tfds.load('patch_camelyon',split=['train[:10%]','test[:10%]','validation[:10%]'],\n",
        "                        data_dir = data_dir,\n",
        "                        download=False,\n",
        "                        shuffle_files=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dpsruvlZUZS"
      },
      "source": [
        "Next we simple transform the data (by the function convert sample described previously) and getting ready for training by splitting it into batches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "TvFSb5XgZUZS"
      },
      "outputs": [],
      "source": [
        "train_dataset       = ds1.map(convert_sample).batch(32)\n",
        "validation_dataset  = ds3.map(convert_sample).batch(32)\n",
        "test_dataset        = ds2.map(convert_sample).batch(32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVOp8zd5ZUZS"
      },
      "source": [
        "The data is then ready to be applied for training, validation, testing etc...below just a very very simple illustration on how to construct and train a model based on the data we have prepared"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUTbw9rWZUZT",
        "outputId": "3ea3c82c-5c94-4352-f1d2-303c62db7be5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "820/820 [==============================] - 513s 623ms/step - loss: 0.6912 - accuracy: 0.5279 - val_loss: 0.6960 - val_accuracy: 0.4931\n",
            "Epoch 2/2\n",
            "820/820 [==============================] - 404s 493ms/step - loss: 0.6935 - accuracy: 0.5043 - val_loss: 0.6956 - val_accuracy: 0.4931\n"
          ]
        }
      ],
      "source": [
        "def first_ccn_model():\n",
        "    input_img = Input(shape=(96,96,3))\n",
        "    \n",
        "    x = Conv2D(16, (3, 3), padding='valid', activation='relu')(input_img)\n",
        "    x = Conv2D(32, (3, 3), padding='valid', activation='relu')(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(128, activation='relu')(x)\n",
        "    x = Dropout(rate=0.2)(x)\n",
        "    y = Dense(2, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=input_img, outputs=y)\n",
        "    return model\n",
        "\n",
        "sgd_opt = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
        "\n",
        "model = first_ccn_model()\n",
        "\n",
        "model.compile(optimizer=sgd_opt,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "hist = model.fit(train_dataset,\n",
        "                 validation_data=validation_dataset,\n",
        "                 epochs=2)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "e72cf8e77b7d4326b9e75b3e7b443795cefd44c8f7193af81f99b8d1febeaf0b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
