{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "Hi there! In this assignment, you will use neural networks (or something else, if you want) to predict values in a regression problem.\n",
    "\n",
    "To get you started, I have provided a complete working example, which is decent but not very impressive.\n",
    "\n",
    "Data is available from Kaggle: https://www.kaggle.com/t/8189b803613d49d7b2021f7f705159ab  where you can also submit your predictions when you are done. The metric used to score this assignment is root mean squared error. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hints to get a good model\n",
    "\n",
    "Be sure to construct a validation set and use it to optimize the parameters of your model.\n",
    "\n",
    "Be sure to scale your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 84) (10000, 84) (40000,)\n"
     ]
    }
   ],
   "source": [
    "# Load data (must be in same folder as this file, which it will be if you simply unzip the assignment).\n",
    "# Note that we don't have any y_test! This way you cannot \"cheat\"!\n",
    "\n",
    "x_train = np.load('X_train.npy')\n",
    "x_test = np.load('X_test.npy')\n",
    "y_train = np.load('y_train.npy')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "print(x_train.shape, x_test.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.0413 - mae: 0.1240\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0234 - mae: 0.1118\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.0228 - mae: 0.1097\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.0225 - mae: 0.1085\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0224 - mae: 0.1080\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.0223 - mae: 0.1076\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0222 - mae: 0.1073\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 5s 4ms/step - loss: 0.0222 - mae: 0.1072\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 6s 5ms/step - loss: 0.0221 - mae: 0.1069\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 6s 4ms/step - loss: 0.0221 - mae: 0.1068\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x246e454ba60>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(84,)),\n",
    "    tf.keras.layers.Dense(32, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(64, activation='sigmoid'),\n",
    "    tf.keras.layers.Dense(1, activation='linear'),\n",
    "    ])\n",
    "model.compile(\n",
    "    loss='mse',\n",
    "    optimizer='sgd',\n",
    "    metrics=['mae'],\n",
    "    )\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code makes predictions and then saves them (after checking they are in correct format)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "y_test_hat = model.predict(x_test)\n",
    "y_test_hat_pd = pd.DataFrame({\n",
    "    'Id': list(range(10000)),\n",
    "    'Predicted': y_test_hat.reshape(-1),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(y_test_hat_pd, pd.DataFrame)\n",
    "assert all(y_test_hat_pd.columns == ['Id', 'Predicted'])\n",
    "assert len(y_test_hat_pd) == 10000\n",
    "\n",
    "# If you pass the checks, the file is saved.\n",
    "y_test_hat_pd.to_csv('y_test_hat.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
