{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Catboost use different names for parameters compared to sklearns model.  \n",
    "Here is a nice guide for catboost https://www.kaggle.com/code/mitribunskiy/tutorial-catboost-overview/notebook  \n",
    "Here is likewise a nice guide: https://coderzcolumn.com/tutorials/machine-learning/catboost-an-in-depth-guide-python#2  \n",
    "Otherwise the official homepage have more information https://catboost.ai/en/docs/  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import\n",
    "# Data wrangling\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Model\n",
    "from catboost import CatBoostClassifier\n",
    "# performance measure\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Grid search\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------ Load data ------\n",
    "# test data (no labels (y_test) since we that way can't see the results)\n",
    "X_test = np.load(\"../Common/data/X_test.npy\")\n",
    "# Validation and training\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "                                                  np.load(\"../Common/data/X_train.npy\"), # X data\n",
    "                                                  np.load(\"../Common/data/y_train.npy\"), # y data (labels)\n",
    "                                                  test_size = 0.5,\n",
    "                                                  random_state = 42\n",
    "                                                  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing around  \n",
    "This is just a bit of playing, next section I will do grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0b15a1bffa042b68804552da0bdeabe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.7793054\tbest: 0.7793054 (0)\ttotal: 37.1ms\tremaining: 9.23s\n",
      "100:\ttest: 0.9494087\tbest: 0.9494087 (100)\ttotal: 2.63s\tremaining: 3.88s\n",
      "Stopped by overfitting detector  (10 iterations wait)\n",
      "\n",
      "bestTest = 0.9496872283\n",
      "bestIteration = 111\n",
      "\n",
      "Shrink model to first 112 iterations.\n",
      "87.57083333333333\n"
     ]
    }
   ],
   "source": [
    "# ------ Create and test model ------\n",
    "model = CatBoostClassifier(\n",
    "                           n_estimators = 1000, # Default = 1000 - How many slow learners to have in the forrest (also called iterations)\n",
    "                           max_leaves = 31, # Default = 31 - The same as max_features in sklearn (how many features to consider)\n",
    "                           min_data_in_leaf = 1, # Default = 1 - The same as min_samples_leaf (The minimum number of samples to have in a leaf)\n",
    "                           max_depth  = 6, # Default = 6 - The max depth of our slow learners \n",
    "                           learning_rate= 0.3, # Default = 0.03 - The learning rate for gradient descent algorithm\n",
    "                           verbose = 100, # Print training process every 100 iteration\n",
    "                           random_state = 42, # For reproducibility\n",
    "                           early_stopping_rounds = 10, #, No default - Preventing overfitting\n",
    "                           bootstrap_type= \"No\",  # I think default it No bootstrapping Bayesian\n",
    "                           eval_metric= 'AUC' # Default: Logloss - Can either evaluate on the loss function or the auccuracy\n",
    "                           loss_function= \"MultiClass\" #  For 2-class classification use 'LogLoss' or 'CrossEntropy'. For multiclass use 'MultiClass'\n",
    "                           )\n",
    "\n",
    "model.fit(X_val, y_val, eval_set=(X_train, y_train), plot = True)\n",
    "y_train_hat = model.predict(X_train)\n",
    "accuracy = accuracy_score(y_train, y_train_hat)\n",
    "print(accuracy * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search  \n",
    "Here I will perform grid search for the final model.  \n",
    "Here you can read more: https://effectiveml.com/using-grid-search-to-optimise-catboost-parameters.html  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters to perform grid-search on:\n",
    "model_params_search = {\n",
    "            \"n_estimators\": [50, 100, 150, 200, 250, 500], # Default = 1000 - How many slow learners to have in the forrest\n",
    "            \"max_leaves\": [5, 10, 20, 30, 100, len(y_val)], # Default = 31 - The same as max_features in sklearn (how many features to consider)\n",
    "            \"min_data_in_leaf\": [1, 2, 3, 4, 5, 6], # Default = 1 - The same as min_samples_leaf (The minimum number of samples to have in a leaf)\n",
    "            \"max_depth\": [1, 2, 3, 4, 5, 6], # Default = 6 - The max depth of our slow learners \n",
    "            \"learning_rate\":  [0.001, 0.01, 0.3, 0.5] , # Default = 0.03 - The learning rate for gradient descent algorithm\n",
    "            \"bootstrap_type\": [\"No\", \"Bayesian\", \"Bernoulli\", \"MVS\"],  # I think default it No bootstrapping Bayesian\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [37], line 18\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Grid search\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# found the guide here: https://youtu.be/N4rqz8Z4XOM \u001b[39;00m\n\u001b[0;32m      9\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[0;32m     10\u001b[0m                            estimator\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     11\u001b[0m                            param_grid \u001b[38;5;241m=\u001b[39m model_params_search,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     15\u001b[0m                            error_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     16\u001b[0m                            )\n\u001b[1;32m---> 18\u001b[0m grid_result \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mfit(X_val, y_val)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(grid_result\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[1;32mc:\\Users\\chris\\OneDrive\\Skrivebord\\studie_repos\\applied_ML_faelles\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    877\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\chris\\OneDrive\\Skrivebord\\studie_repos\\applied_ML_faelles\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1379\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1378\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1379\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\chris\\OneDrive\\Skrivebord\\studie_repos\\applied_ML_faelles\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    815\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    817\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    819\u001b[0m         )\n\u001b[0;32m    820\u001b[0m     )\n\u001b[1;32m--> 822\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    823\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    824\u001b[0m         clone(base_estimator),\n\u001b[0;32m    825\u001b[0m         X,\n\u001b[0;32m    826\u001b[0m         y,\n\u001b[0;32m    827\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    828\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    829\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    830\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    831\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    832\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    833\u001b[0m     )\n\u001b[0;32m    834\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    835\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    836\u001b[0m     )\n\u001b[0;32m    837\u001b[0m )\n\u001b[0;32m    839\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    840\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    844\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\chris\\OneDrive\\Skrivebord\\studie_repos\\applied_ML_faelles\\.venv\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\chris\\OneDrive\\Skrivebord\\studie_repos\\applied_ML_faelles\\.venv\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\chris\\OneDrive\\Skrivebord\\studie_repos\\applied_ML_faelles\\.venv\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\chris\\OneDrive\\Skrivebord\\studie_repos\\applied_ML_faelles\\.venv\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\chris\\OneDrive\\Skrivebord\\studie_repos\\applied_ML_faelles\\.venv\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\chris\\OneDrive\\Skrivebord\\studie_repos\\applied_ML_faelles\\.venv\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\chris\\OneDrive\\Skrivebord\\studie_repos\\applied_ML_faelles\\.venv\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\chris\\OneDrive\\Skrivebord\\studie_repos\\applied_ML_faelles\\.venv\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\chris\\OneDrive\\Skrivebord\\studie_repos\\applied_ML_faelles\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[1;32mc:\\Users\\chris\\OneDrive\\Skrivebord\\studie_repos\\applied_ML_faelles\\.venv\\lib\\site-packages\\catboost\\core.py:5128\u001b[0m, in \u001b[0;36mCatBoostClassifier.fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   5125\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m params:\n\u001b[0;32m   5126\u001b[0m     CatBoostClassifier\u001b[39m.\u001b[39m_check_is_compatible_loss(params[\u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m-> 5128\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, cat_features, text_features, embedding_features, \u001b[39mNone\u001b[39;49;00m, sample_weight, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, baseline, use_best_model,\n\u001b[0;32m   5129\u001b[0m           eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period,\n\u001b[0;32m   5130\u001b[0m           silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n\u001b[0;32m   5131\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\chris\\OneDrive\\Skrivebord\\studie_repos\\applied_ML_faelles\\.venv\\lib\\site-packages\\catboost\\core.py:2339\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   2336\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(X, PATH_TYPES \u001b[39m+\u001b[39m (Pool,)):\n\u001b[0;32m   2337\u001b[0m     \u001b[39mraise\u001b[39;00m CatBoostError(\u001b[39m\"\u001b[39m\u001b[39my may be None only when X is an instance of catboost.Pool or string\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 2339\u001b[0m train_params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_train_params(\n\u001b[0;32m   2340\u001b[0m     X\u001b[39m=\u001b[39;49mX, y\u001b[39m=\u001b[39;49my, cat_features\u001b[39m=\u001b[39;49mcat_features, text_features\u001b[39m=\u001b[39;49mtext_features, embedding_features\u001b[39m=\u001b[39;49membedding_features,\n\u001b[0;32m   2341\u001b[0m     pairs\u001b[39m=\u001b[39;49mpairs, sample_weight\u001b[39m=\u001b[39;49msample_weight, group_id\u001b[39m=\u001b[39;49mgroup_id, group_weight\u001b[39m=\u001b[39;49mgroup_weight,\n\u001b[0;32m   2342\u001b[0m     subgroup_id\u001b[39m=\u001b[39;49msubgroup_id, pairs_weight\u001b[39m=\u001b[39;49mpairs_weight, baseline\u001b[39m=\u001b[39;49mbaseline, use_best_model\u001b[39m=\u001b[39;49muse_best_model,\n\u001b[0;32m   2343\u001b[0m     eval_set\u001b[39m=\u001b[39;49meval_set, verbose\u001b[39m=\u001b[39;49mverbose, logging_level\u001b[39m=\u001b[39;49mlogging_level, plot\u001b[39m=\u001b[39;49mplot, plot_file\u001b[39m=\u001b[39;49mplot_file,\n\u001b[0;32m   2344\u001b[0m     column_description\u001b[39m=\u001b[39;49mcolumn_description, verbose_eval\u001b[39m=\u001b[39;49mverbose_eval, metric_period\u001b[39m=\u001b[39;49mmetric_period,\n\u001b[0;32m   2345\u001b[0m     silent\u001b[39m=\u001b[39;49msilent, early_stopping_rounds\u001b[39m=\u001b[39;49mearly_stopping_rounds, save_snapshot\u001b[39m=\u001b[39;49msave_snapshot,\n\u001b[0;32m   2346\u001b[0m     snapshot_file\u001b[39m=\u001b[39;49msnapshot_file, snapshot_interval\u001b[39m=\u001b[39;49msnapshot_interval, init_model\u001b[39m=\u001b[39;49minit_model,\n\u001b[0;32m   2347\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks\n\u001b[0;32m   2348\u001b[0m )\n\u001b[0;32m   2349\u001b[0m params \u001b[39m=\u001b[39m train_params[\u001b[39m\"\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   2350\u001b[0m train_pool \u001b[39m=\u001b[39m train_params[\u001b[39m\"\u001b[39m\u001b[39mtrain_pool\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\chris\\OneDrive\\Skrivebord\\studie_repos\\applied_ML_faelles\\.venv\\lib\\site-packages\\catboost\\core.py:2220\u001b[0m, in \u001b[0;36mCatBoost._prepare_train_params\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks)\u001b[0m\n\u001b[0;32m   2217\u001b[0m text_features \u001b[39m=\u001b[39m _process_feature_indices(text_features, X, params, \u001b[39m'\u001b[39m\u001b[39mtext_features\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m   2218\u001b[0m embedding_features \u001b[39m=\u001b[39m _process_feature_indices(embedding_features, X, params, \u001b[39m'\u001b[39m\u001b[39membedding_features\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 2220\u001b[0m train_pool \u001b[39m=\u001b[39m _build_train_pool(X, y, cat_features, text_features, embedding_features, pairs,\n\u001b[0;32m   2221\u001b[0m                                sample_weight, group_id, group_weight, subgroup_id, pairs_weight,\n\u001b[0;32m   2222\u001b[0m                                baseline, column_description)\n\u001b[0;32m   2223\u001b[0m \u001b[39mif\u001b[39;00m train_pool\u001b[39m.\u001b[39mis_empty_:\n\u001b[0;32m   2224\u001b[0m     \u001b[39mraise\u001b[39;00m CatBoostError(\u001b[39m\"\u001b[39m\u001b[39mX is empty.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\chris\\OneDrive\\Skrivebord\\studie_repos\\applied_ML_faelles\\.venv\\lib\\site-packages\\catboost\\core.py:1438\u001b[0m, in \u001b[0;36m_build_train_pool\u001b[1;34m(X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, column_description)\u001b[0m\n\u001b[0;32m   1436\u001b[0m     \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1437\u001b[0m         \u001b[39mraise\u001b[39;00m CatBoostError(\u001b[39m\"\u001b[39m\u001b[39my has not initialized in fit(): X is not catboost.Pool object, y must be not None in fit().\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1438\u001b[0m     train_pool \u001b[39m=\u001b[39m Pool(X, y, cat_features\u001b[39m=\u001b[39;49mcat_features, text_features\u001b[39m=\u001b[39;49mtext_features, embedding_features\u001b[39m=\u001b[39;49membedding_features, pairs\u001b[39m=\u001b[39;49mpairs, weight\u001b[39m=\u001b[39;49msample_weight, group_id\u001b[39m=\u001b[39;49mgroup_id,\n\u001b[0;32m   1439\u001b[0m                       group_weight\u001b[39m=\u001b[39;49mgroup_weight, subgroup_id\u001b[39m=\u001b[39;49msubgroup_id, pairs_weight\u001b[39m=\u001b[39;49mpairs_weight, baseline\u001b[39m=\u001b[39;49mbaseline)\n\u001b[0;32m   1440\u001b[0m \u001b[39mreturn\u001b[39;00m train_pool\n",
      "File \u001b[1;32mc:\\Users\\chris\\OneDrive\\Skrivebord\\studie_repos\\applied_ML_faelles\\.venv\\lib\\site-packages\\catboost\\core.py:792\u001b[0m, in \u001b[0;36mPool.__init__\u001b[1;34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, column_description, pairs, delimiter, has_header, ignore_csv_quoting, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m    786\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(feature_names, PATH_TYPES):\n\u001b[0;32m    787\u001b[0m             \u001b[39mraise\u001b[39;00m CatBoostError(\n\u001b[0;32m    788\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mfeature_names must be None or have non-string type when the pool is created from \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    789\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mpython objects.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    790\u001b[0m             )\n\u001b[1;32m--> 792\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n\u001b[0;32m    793\u001b[0m                    group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\n\u001b[0;32m    794\u001b[0m \u001b[39msuper\u001b[39m(Pool, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\chris\\OneDrive\\Skrivebord\\studie_repos\\applied_ML_faelles\\.venv\\lib\\site-packages\\catboost\\core.py:1419\u001b[0m, in \u001b[0;36mPool._init\u001b[1;34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\u001b[0m\n\u001b[0;32m   1417\u001b[0m \u001b[39mif\u001b[39;00m feature_tags \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1418\u001b[0m     feature_tags \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_transform_tags(feature_tags, feature_names)\n\u001b[1;32m-> 1419\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_pool(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n\u001b[0;32m   1420\u001b[0m                 group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\n",
      "File \u001b[1;32m_catboost.pyx:3953\u001b[0m, in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_catboost.pyx:4020\u001b[0m, in \u001b[0;36m_catboost._PoolBase._init_pool\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_catboost.pyx:3929\u001b[0m, in \u001b[0;36m_catboost._PoolBase._init_objects_order_layout_pool\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_catboost.pyx:3649\u001b[0m, in \u001b[0;36m_catboost._PoolBase._set_label_objects_order\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2032.0_x64__qbz5n2kfra8p0\\lib\\abc.py:119\u001b[0m, in \u001b[0;36mABCMeta.__instancecheck__\u001b[1;34m(cls, instance)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__instancecheck__\u001b[39m(\u001b[39mcls\u001b[39m, instance):\n\u001b[0;32m    118\u001b[0m     \u001b[39m\"\"\"Override for isinstance(instance, cls).\"\"\"\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m _abc_instancecheck(\u001b[39mcls\u001b[39;49m, instance)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = CatBoostClassifier(\n",
    "                           verbose = 100, # Print training process every 100 iteration\n",
    "                           random_state = 42, # For reproducibility\n",
    "                           early_stopping_rounds = 10 #, No default - Preventing overfitting\n",
    "                           )\n",
    "\n",
    "# Grid search\n",
    "# found the guide here: https://youtu.be/N4rqz8Z4XOM \n",
    "grid_search = GridSearchCV(\n",
    "                           estimator=model,\n",
    "                           param_grid = model_params_search,\n",
    "                           n_jobs=1,\n",
    "                           cv = 3,\n",
    "                           scoring = \"accuracy\",\n",
    "                           error_score=0\n",
    "                           )\n",
    "\n",
    "grid_result = grid_search.fit(X_val, y_val)\n",
    "print(grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'nan_mode': Min\n",
      "'eval_metric': MultiClass\n",
      "'iterations': 720\n",
      "'sampling_frequency': PerTree\n",
      "'leaf_estimation_method': Newton\n",
      "'od_pval': 0\n",
      "'grow_policy': SymmetricTree\n",
      "'penalties_coefficient': 1\n",
      "'boosting_type': Plain\n",
      "'model_shrink_mode': Constant\n",
      "'feature_border_type': GreedyLogSum\n",
      "'bayesian_matrix_reg': 0.10000000149011612\n",
      "'eval_fraction': 0\n",
      "'force_unit_auto_pair_weights': False\n",
      "'l2_leaf_reg': 3\n",
      "'random_strength': 1\n",
      "'od_type': Iter\n",
      "'rsm': 1\n",
      "'boost_from_average': False\n",
      "'model_size_reg': 0.5\n",
      "'pool_metainfo_options': {'tags': {}}\n",
      "'use_best_model': True\n",
      "'od_wait': 6\n",
      "'class_names': [0, 1, 2]\n",
      "'random_seed': 42\n",
      "'depth': 2\n",
      "'posterior_sampling': False\n",
      "'border_count': 254\n",
      "'bagging_temperature': 1\n",
      "'classes_count': 0\n",
      "'auto_class_weights': None\n",
      "'sparse_features_conflict_fraction': 0\n",
      "'leaf_estimation_backtracking': AnyImprovement\n",
      "'best_model_min_trees': 1\n",
      "'model_shrink_rate': 0\n",
      "'min_data_in_leaf': 2\n",
      "'loss_function': MultiClass\n",
      "'learning_rate': 0.30000001192092896\n",
      "'score_function': Cosine\n",
      "'task_type': CPU\n",
      "'leaf_estimation_iterations': 1\n",
      "'bootstrap_type': Bayesian\n",
      "'max_leaves': 31\n"
     ]
    }
   ],
   "source": [
    "final_model = model.set_params(\n",
    "    grid_result.best_params_\n",
    ")\n",
    "# final_model.fit(np.concatenate(X_train, X_val), np.concatenate(y_train, y_val))\n",
    "final_model.fit(X_val, y_val)\n",
    "final_model_pred = final_model.predict(X_train)\n",
    "accuracy = accuracy_score(y_train, final_model_pred)\n",
    "print(accuracy * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import\n",
    "# Data wrangling\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "# Model\n",
    "from catboost import CatBoostClassifier\n",
    "# performance measure\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Grid search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# ------ Load data ------\n",
    "# test data (no labels (y_test) since we that way can't see the results)\n",
    "X_test = np.load(\"../Common/data/X_test.npy\")\n",
    "# Validation and training\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "                                                  np.load(\"../Common/data/X_train.npy\"), # X data\n",
    "                                                  np.load(\"../Common/data/y_train.npy\"), # y data (labels)\n",
    "                                                  test_size = 0.5,\n",
    "                                                  random_state = 42\n",
    "                                                  )\n",
    "# ------ Create and train model ------ \n",
    "final_model = CatBoostClassifier(\n",
    "                           verbose = 100, # Print training process every 100 iteration\n",
    "                           random_state = 42, # For reproducibility\n",
    "                           early_stopping_rounds = 10 #, No default - Preventing overfitting\n",
    "                           )\n",
    "best_params = {\n",
    "\n",
    "}\n",
    "final_model = final_model.set_params(best_params)\n",
    "final_model.fit(np.concatenate(X_train, X_val), np.concatenate(y_train, y_val))\n",
    "\n",
    "# ------ Create and save predictions ------\n",
    "final_model_pred = final_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_train, final_model_pred)\n",
    "\n",
    "\n",
    "\n",
    "y_test_hat = final_model.predict(X_test)\n",
    "y_test_hat_pd = pd.DataFrame({\n",
    "    'Id': list(range(len(y_test_hat))),\n",
    "    'Category': y_test_hat,\n",
    "})\n",
    "\n",
    "\n",
    "# After you make your predictions, you should submit them on the Kaggle webpage for our competition.\n",
    "# Below is a small check that your output has the right type and shape\n",
    "assert isinstance(y_test_hat_pd, pd.DataFrame)\n",
    "assert all(y_test_hat_pd.columns == ['Id', 'Category'])\n",
    "\n",
    "# If you pass the checks, the file is saved.\n",
    "y_test_hat_pd.to_csv('y_test_hat.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fe82a64eee2b8d17df1c98106d8e23656cf3c584b17313c850b9d654a3f19002"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
